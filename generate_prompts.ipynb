{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c38cb70-bf7d-4afd-ad47-a7f7122257ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pathlib\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel, LlamaForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Any\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed1d756-0574-4d50-9091-3505034fbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15abfa57-a0e6-4791-a95f-128460c4aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='huggingface/meta-llama/Llama-2-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "pad_token_id=32000\n",
      "model_input_names=['input_ids', 'attention_mask']\n",
      "CPU times: user 32.7 ms, sys: 7.82 ms, total: 40.5 ms\n",
      "Wall time: 41.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface/meta-llama/Llama-2-7b-hf\")\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\n",
    "print(f\"{repr(tokenizer)}\\npad_token_id={tokenizer.pad_token_id}\\nmodel_input_names={tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6febed68-985f-4722-ae3a-25b555b22aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deda467a697448ef92493789e858f1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba18ff036054eb8b04efba66dc77dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d293ae092849b19d2a72dd3d52721e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ee1c4693a54a489adf86a928ee2294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4f7753b803420e932acc4bccdf13ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9078805a0efd4c518395e97934e1a8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efbfcdce72741e88bbad48eed51fc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80a67730a384689821c29dd3590374e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32001, 5120)\n",
      "    (layers): ModuleList(\n",
      "      (0-39): 40 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
      "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
      "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=5120, out_features=32001, bias=False)\n",
      ")\n",
      "CPU times: user 34 s, sys: 1min 19s, total: 1min 53s\n",
      "Wall time: 31min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference uses fp16\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-hf\", torch_dtype=torch.float16)\n",
    "model = model.to(device)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4634e041-bd6f-40c5-86bc-2c2f125cd053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey, are you conscious? Can you talk to me?\\nThe other day, I was in the bathroom when I heard my son, who was in the living room, yelling for me. I hurried out and found him standing in front of the TV, holding his head.\\n“Mommy, I’m going to die!” he said.\\n“What? Why?” I asked, rushing to his side.\\n“I’m going to die because I’m not conscious!” he said.\\n“You’re not conscious? What do you mean?” I asked.\\n“I mean, I’m not conscious!” he said, pointing to his head.\\n“You’re not conscious?” I asked.\\n“I’m not conscious!” he said.\\n“I don’t know,” he said. “I just know I’m not conscious.”\\n“What do you mean you’re not conscious?” I asked.\\n“I don’t know,” he said. “I just know I’m not conscious.”\\n“What do you mean you’re not conscious?” I asked, getting frustrated.\\n“I don’t know,” he said. “I just know I’m not conscious.”\\n“What do you mean you’re not conscious?” I asked, getting more frustrated.\\n“I don’t know,” he said. “I just know I'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=256)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f24a95-5ff7-45c3-acd1-d24036820944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
