{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062a9473-ec3c-4f1c-80de-66912972bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from typing import List, Dict, Union, Tuple, NamedTuple\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafd5a38-0166-47b6-aed4-7ae66bd7bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "job_dir = f\"models/xgb/{ts}\"\n",
    "pathlib.Path(job_dir).mkdir(parents=True, exist_ok=True)\n",
    "num_boost_round: int = 100\n",
    "lr: Tuple[float, float] = (1e-3, 1e-3)\n",
    "feature_fraction: Tuple[float, float] = (1, 1)\n",
    "min_data_in_leaf: Tuple[int, int] = (20, 20)\n",
    "objective: str = \"binary:logistic\"\n",
    "n_trials: int = 1\n",
    "label = \"generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e822fad3-d0a9-4094-9efb-60cde058d454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39120 entries, 0 to 39119\n",
      "Columns: 29780 entries, essay_id to tf_Ġzygomatic\n",
      "dtypes: float32(29765), int16(2), int32(5), int8(1), object(7)\n",
      "memory usage: 4.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/features.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb8e82b-a582-4d2a-88e1-d4a4c85a1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29768 features\n",
      "['ch_digit_frac', 'ch_len', 'ch_letter_frac', 'ch_punc_frac', 'ch_repeat_char_frac', 'ch_space_frac', 'ch_upper_frac', 'tf_0', 'tf_00', 'tf_000', 'tf_03', 'tf_1', 'tf_10', 'tf_11', 'tf_12', 'tf_13', 'tf_14', 'tf_15', 'tf_16', 'tf_17', 'tf_18', 'tf_19', 'tf_199', 'tf_1990', 'tf_2', 'tf_20', 'tf_200', 'tf_2002', 'tf_21', 'tf_23', 'tf_24', 'tf_25', 'tf_27', 'tf_28', 'tf_3', 'tf_30', 'tf_31', 'tf_32', 'tf_33', 'tf_34', 'tf_38', 'tf_39', 'tf_4', 'tf_40', 'tf_41', 'tf_43', 'tf_45', 'tf_5', 'tf_50', 'tf_538', 'tf_58', 'tf_6', 'tf_60', 'tf_62', 'tf_7', 'tf_70', 'tf_74', 'tf_76', 'tf_79', 'tf_8', 'tf_87', 'tf_9', 'tf_a', 'tf_aa', 'tf_aae', 'tf_aage', 'tf_aaion', 'tf_ab', 'tf_aban', 'tf_abe', 'tf_abel', 'tf_aber', 'tf_abet', 'tf_abeth', 'tf_abil', 'tf_abilites', 'tf_abilitie', 'tf_abilities', 'tf_ability', 'tf_abill', 'tf_abilty', 'tf_abitable', 'tf_abital', 'tf_abl', 'tf_able', 'tf_abled', 'tf_ables', 'tf_abling', 'tf_ablish', 'tf_ablished', 'tf_ablities', 'tf_ablity', 'tf_ably', 'tf_about', 'tf_abra', 'tf_abraeus', 'tf_abs', 'tf_abul', 'tf_aby', 'tf_ac']\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "prefixes = [\"ch_\", \"ts_\", \"va_\", \"tf_\"]\n",
    "for col in df.columns:\n",
    "    for prefix in prefixes:\n",
    "        if col.startswith(prefix):\n",
    "            features.append(col)\n",
    "features.sort()\n",
    "print(f\"{len(features)} features\\n{features[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fd2b91-247a-4891-9859-478bb1d42583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val%=0.0293, len(tra)=37,974, len(val)=1,146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907</td>\n",
       "      <td>0.791449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>0.208551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count   percent\n",
       "generated                 \n",
       "1            907  0.791449\n",
       "0            239  0.208551"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(tra[features], tra[label], test_size=0.2)\n",
    "\n",
    "tra = df[df[\"white_sim\"]>=0.45]\n",
    "val = df[df[\"white_sim\"]<0.45]\n",
    "t = len(tra)\n",
    "v = len(val)\n",
    "n = t+v\n",
    "print(f\"val%={v/n:.4f}, len(tra)={t:,}, len(val)={v:,}\")\n",
    "dtrain = xgb.DMatrix(tra[features], tra[label], enable_categorical=False)\n",
    "dval = xgb.DMatrix(val[features], val[label], enable_categorical=False)\n",
    "pdx.value_counts(val[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df30c12e-601b-4dcb-8ab9-90f3beb13b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.51076\tval-logloss:1.08934\n",
      "[40]\ttrain-logloss:0.12861\tval-logloss:0.38881\n",
      "[80]\ttrain-logloss:0.06243\tval-logloss:0.23493\n",
      "[120]\ttrain-logloss:0.03940\tval-logloss:0.17246\n",
      "[160]\ttrain-logloss:0.02863\tval-logloss:0.13892\n",
      "[200]\ttrain-logloss:0.02209\tval-logloss:0.11792\n",
      "[240]\ttrain-logloss:0.01776\tval-logloss:0.10540\n",
      "[280]\ttrain-logloss:0.01470\tval-logloss:0.09464\n",
      "[320]\ttrain-logloss:0.01241\tval-logloss:0.08805\n",
      "[360]\ttrain-logloss:0.01070\tval-logloss:0.08333\n",
      "[400]\ttrain-logloss:0.00941\tval-logloss:0.07873\n",
      "[440]\ttrain-logloss:0.00840\tval-logloss:0.07597\n",
      "[480]\ttrain-logloss:0.00755\tval-logloss:0.07408\n",
      "[520]\ttrain-logloss:0.00687\tval-logloss:0.07204\n",
      "[560]\ttrain-logloss:0.00629\tval-logloss:0.07023\n",
      "[600]\ttrain-logloss:0.00585\tval-logloss:0.06919\n",
      "[640]\ttrain-logloss:0.00546\tval-logloss:0.06826\n",
      "[680]\ttrain-logloss:0.00515\tval-logloss:0.06820\n",
      "[720]\ttrain-logloss:0.00488\tval-logloss:0.06712\n",
      "[760]\ttrain-logloss:0.00465\tval-logloss:0.06672\n",
      "[800]\ttrain-logloss:0.00444\tval-logloss:0.06618\n",
      "[840]\ttrain-logloss:0.00425\tval-logloss:0.06550\n",
      "[880]\ttrain-logloss:0.00410\tval-logloss:0.06523\n",
      "[920]\ttrain-logloss:0.00396\tval-logloss:0.06498\n",
      "[960]\ttrain-logloss:0.00384\tval-logloss:0.06529\n",
      "[1000]\ttrain-logloss:0.00372\tval-logloss:0.06487\n",
      "[1040]\ttrain-logloss:0.00361\tval-logloss:0.06460\n",
      "[1080]\ttrain-logloss:0.00352\tval-logloss:0.06483\n",
      "[1120]\ttrain-logloss:0.00343\tval-logloss:0.06477\n",
      "best score 0.06451 at iteration 1020\n",
      "CPU times: user 2h 53min 44s, sys: 34min 32s, total: 3h 28min 17s\n",
      "Wall time: 16min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.train(\n",
    "   params={\n",
    "       \"objective\": objective,\n",
    "       \"learning_rate\": 5e-2,\n",
    "       \"min_child_weight\": 20,\n",
    "       \"colsample_bytree\": 0.5,\n",
    "       \"max_depth\": 6,\n",
    "   },\n",
    "   dtrain=dtrain,\n",
    "   num_boost_round=2000,\n",
    "   evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "   verbose_eval=40,\n",
    "   early_stopping_rounds=100,\n",
    ")\n",
    "print(f\"best score {model.best_score:.5f} at iteration {model.best_iteration}\")\n",
    "model.save_model(f\"{job_dir}/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6da2370-9acb-42fa-894f-c4da29da6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.9979\n",
      "y_pred=(1146,)\n",
      "[0.9656257  0.96811175 0.99439245 0.01315708 0.99998796]\n",
      "CPU times: user 228 ms, sys: 388 ms, total: 616 ms\n",
      "Wall time: 62.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_true = val[label].tolist()\n",
    "y_pred = model.predict(data=dval, iteration_range=(0, model.best_iteration+1))\n",
    "auc = roc_auc_score(y_true, y_pred, average=\"macro\")\n",
    "print(f\"auc={auc:.4f}\")\n",
    "print(f\"y_pred={y_pred.shape}\\n{y_pred[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f793a39d-7bce-4472-aef3-bacde89ee929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models/xgb/20240119_155859/importance.csv\n",
      "CPU times: user 15.2 ms, sys: 32.4 ms, total: 47.5 ms\n",
      "Wall time: 4.85 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>781.810486</td>\n",
       "      <td>490.538818</td>\n",
       "      <td>485.316528</td>\n",
       "      <td>336.407135</td>\n",
       "      <td>288.690765</td>\n",
       "      <td>288.211456</td>\n",
       "      <td>229.231964</td>\n",
       "      <td>219.743591</td>\n",
       "      <td>209.669327</td>\n",
       "      <td>181.665131</td>\n",
       "      <td>179.183456</td>\n",
       "      <td>169.901947</td>\n",
       "      <td>168.316895</td>\n",
       "      <td>167.481339</td>\n",
       "      <td>151.356659</td>\n",
       "      <td>143.653076</td>\n",
       "      <td>140.939529</td>\n",
       "      <td>110.069252</td>\n",
       "      <td>101.857819</td>\n",
       "      <td>93.974632</td>\n",
       "      <td>90.115738</td>\n",
       "      <td>88.624748</td>\n",
       "      <td>86.975922</td>\n",
       "      <td>85.581299</td>\n",
       "      <td>77.569267</td>\n",
       "      <td>77.131325</td>\n",
       "      <td>75.604225</td>\n",
       "      <td>70.384636</td>\n",
       "      <td>69.825089</td>\n",
       "      <td>69.298241</td>\n",
       "      <td>67.570801</td>\n",
       "      <td>66.250443</td>\n",
       "      <td>63.203785</td>\n",
       "      <td>62.863422</td>\n",
       "      <td>61.277332</td>\n",
       "      <td>61.199062</td>\n",
       "      <td>57.946815</td>\n",
       "      <td>57.901653</td>\n",
       "      <td>56.458355</td>\n",
       "      <td>54.44944</td>\n",
       "      <td>53.377113</td>\n",
       "      <td>52.523922</td>\n",
       "      <td>50.847752</td>\n",
       "      <td>50.176514</td>\n",
       "      <td>46.688572</td>\n",
       "      <td>46.042809</td>\n",
       "      <td>44.76157</td>\n",
       "      <td>43.390869</td>\n",
       "      <td>42.235153</td>\n",
       "      <td>40.835976</td>\n",
       "      <td>40.318829</td>\n",
       "      <td>40.199787</td>\n",
       "      <td>39.128548</td>\n",
       "      <td>36.081169</td>\n",
       "      <td>36.04126</td>\n",
       "      <td>34.270901</td>\n",
       "      <td>33.954178</td>\n",
       "      <td>33.37429</td>\n",
       "      <td>32.947266</td>\n",
       "      <td>31.265629</td>\n",
       "      <td>30.823727</td>\n",
       "      <td>30.135227</td>\n",
       "      <td>29.626429</td>\n",
       "      <td>29.362932</td>\n",
       "      <td>28.551178</td>\n",
       "      <td>27.447458</td>\n",
       "      <td>26.943707</td>\n",
       "      <td>26.039213</td>\n",
       "      <td>25.908745</td>\n",
       "      <td>25.699692</td>\n",
       "      <td>25.50363</td>\n",
       "      <td>24.424545</td>\n",
       "      <td>24.239599</td>\n",
       "      <td>24.071177</td>\n",
       "      <td>23.032135</td>\n",
       "      <td>22.710127</td>\n",
       "      <td>22.611753</td>\n",
       "      <td>22.584135</td>\n",
       "      <td>21.534424</td>\n",
       "      <td>21.493031</td>\n",
       "      <td>21.450483</td>\n",
       "      <td>21.356768</td>\n",
       "      <td>20.933449</td>\n",
       "      <td>20.710167</td>\n",
       "      <td>20.395821</td>\n",
       "      <td>20.098389</td>\n",
       "      <td>19.472715</td>\n",
       "      <td>19.420181</td>\n",
       "      <td>19.391479</td>\n",
       "      <td>18.932508</td>\n",
       "      <td>18.800821</td>\n",
       "      <td>18.507572</td>\n",
       "      <td>18.358309</td>\n",
       "      <td>18.106339</td>\n",
       "      <td>17.710629</td>\n",
       "      <td>17.690317</td>\n",
       "      <td>17.369865</td>\n",
       "      <td>17.249359</td>\n",
       "      <td>17.130758</td>\n",
       "      <td>16.952984</td>\n",
       "      <td>16.912823</td>\n",
       "      <td>16.879992</td>\n",
       "      <td>16.801064</td>\n",
       "      <td>16.675583</td>\n",
       "      <td>16.646465</td>\n",
       "      <td>16.53372</td>\n",
       "      <td>16.395014</td>\n",
       "      <td>16.263538</td>\n",
       "      <td>16.058931</td>\n",
       "      <td>15.312901</td>\n",
       "      <td>14.979809</td>\n",
       "      <td>14.0781</td>\n",
       "      <td>13.79497</td>\n",
       "      <td>13.216605</td>\n",
       "      <td>13.105409</td>\n",
       "      <td>13.085265</td>\n",
       "      <td>12.985317</td>\n",
       "      <td>12.907841</td>\n",
       "      <td>12.708452</td>\n",
       "      <td>12.667187</td>\n",
       "      <td>12.591174</td>\n",
       "      <td>12.368817</td>\n",
       "      <td>12.266745</td>\n",
       "      <td>12.248855</td>\n",
       "      <td>12.22839</td>\n",
       "      <td>12.214986</td>\n",
       "      <td>12.189629</td>\n",
       "      <td>12.023846</td>\n",
       "      <td>11.685711</td>\n",
       "      <td>11.51645</td>\n",
       "      <td>11.498635</td>\n",
       "      <td>11.412957</td>\n",
       "      <td>11.209677</td>\n",
       "      <td>10.870028</td>\n",
       "      <td>10.845504</td>\n",
       "      <td>10.8053</td>\n",
       "      <td>10.681151</td>\n",
       "      <td>10.634077</td>\n",
       "      <td>10.436765</td>\n",
       "      <td>10.416463</td>\n",
       "      <td>10.245605</td>\n",
       "      <td>9.8927</td>\n",
       "      <td>9.564544</td>\n",
       "      <td>9.530143</td>\n",
       "      <td>9.510941</td>\n",
       "      <td>9.464931</td>\n",
       "      <td>9.168464</td>\n",
       "      <td>9.160788</td>\n",
       "      <td>9.05891</td>\n",
       "      <td>9.055192</td>\n",
       "      <td>8.884005</td>\n",
       "      <td>8.883018</td>\n",
       "      <td>8.678984</td>\n",
       "      <td>8.647542</td>\n",
       "      <td>8.55966</td>\n",
       "      <td>8.511078</td>\n",
       "      <td>8.084966</td>\n",
       "      <td>8.036461</td>\n",
       "      <td>7.956953</td>\n",
       "      <td>7.909729</td>\n",
       "      <td>7.55541</td>\n",
       "      <td>7.534116</td>\n",
       "      <td>7.440822</td>\n",
       "      <td>7.436173</td>\n",
       "      <td>7.433044</td>\n",
       "      <td>7.310189</td>\n",
       "      <td>7.203867</td>\n",
       "      <td>7.152648</td>\n",
       "      <td>7.146918</td>\n",
       "      <td>7.11026</td>\n",
       "      <td>7.101671</td>\n",
       "      <td>6.941996</td>\n",
       "      <td>6.941086</td>\n",
       "      <td>6.813098</td>\n",
       "      <td>6.753841</td>\n",
       "      <td>6.731386</td>\n",
       "      <td>6.682386</td>\n",
       "      <td>6.637693</td>\n",
       "      <td>6.609685</td>\n",
       "      <td>6.514729</td>\n",
       "      <td>6.467379</td>\n",
       "      <td>6.006093</td>\n",
       "      <td>5.971101</td>\n",
       "      <td>5.930752</td>\n",
       "      <td>5.877871</td>\n",
       "      <td>5.752261</td>\n",
       "      <td>5.685339</td>\n",
       "      <td>5.64645</td>\n",
       "      <td>5.622975</td>\n",
       "      <td>5.396545</td>\n",
       "      <td>5.314053</td>\n",
       "      <td>5.280446</td>\n",
       "      <td>5.232251</td>\n",
       "      <td>5.213174</td>\n",
       "      <td>5.166775</td>\n",
       "      <td>5.094082</td>\n",
       "      <td>5.069883</td>\n",
       "      <td>5.025868</td>\n",
       "      <td>4.883653</td>\n",
       "      <td>4.853292</td>\n",
       "      <td>4.834744</td>\n",
       "      <td>4.783371</td>\n",
       "      <td>4.732041</td>\n",
       "      <td>4.612059</td>\n",
       "      <td>4.603532</td>\n",
       "      <td>4.580497</td>\n",
       "      <td>4.535528</td>\n",
       "      <td>4.528878</td>\n",
       "      <td>4.481597</td>\n",
       "      <td>4.420849</td>\n",
       "      <td>4.358688</td>\n",
       "      <td>4.354087</td>\n",
       "      <td>4.349886</td>\n",
       "      <td>4.252539</td>\n",
       "      <td>4.079772</td>\n",
       "      <td>4.05571</td>\n",
       "      <td>3.973468</td>\n",
       "      <td>3.923386</td>\n",
       "      <td>3.863719</td>\n",
       "      <td>3.863282</td>\n",
       "      <td>3.832214</td>\n",
       "      <td>3.77792</td>\n",
       "      <td>3.740831</td>\n",
       "      <td>3.656284</td>\n",
       "      <td>3.606041</td>\n",
       "      <td>3.538441</td>\n",
       "      <td>3.515561</td>\n",
       "      <td>3.495106</td>\n",
       "      <td>3.396851</td>\n",
       "      <td>3.372038</td>\n",
       "      <td>3.335905</td>\n",
       "      <td>3.179139</td>\n",
       "      <td>3.097436</td>\n",
       "      <td>3.039652</td>\n",
       "      <td>3.02588</td>\n",
       "      <td>3.02353</td>\n",
       "      <td>3.010557</td>\n",
       "      <td>2.998088</td>\n",
       "      <td>2.99721</td>\n",
       "      <td>2.875458</td>\n",
       "      <td>2.818633</td>\n",
       "      <td>2.782501</td>\n",
       "      <td>2.717593</td>\n",
       "      <td>2.684284</td>\n",
       "      <td>2.676867</td>\n",
       "      <td>2.652729</td>\n",
       "      <td>2.641006</td>\n",
       "      <td>2.593753</td>\n",
       "      <td>2.583044</td>\n",
       "      <td>2.550439</td>\n",
       "      <td>2.528988</td>\n",
       "      <td>2.523669</td>\n",
       "      <td>2.436218</td>\n",
       "      <td>2.430205</td>\n",
       "      <td>2.418217</td>\n",
       "      <td>2.374122</td>\n",
       "      <td>2.238956</td>\n",
       "      <td>2.226804</td>\n",
       "      <td>2.208097</td>\n",
       "      <td>2.202519</td>\n",
       "      <td>2.190012</td>\n",
       "      <td>2.185219</td>\n",
       "      <td>2.170147</td>\n",
       "      <td>2.127258</td>\n",
       "      <td>2.09442</td>\n",
       "      <td>2.03263</td>\n",
       "      <td>2.009032</td>\n",
       "      <td>2.008704</td>\n",
       "      <td>1.952991</td>\n",
       "      <td>1.919455</td>\n",
       "      <td>1.857847</td>\n",
       "      <td>1.850523</td>\n",
       "      <td>1.818397</td>\n",
       "      <td>1.776517</td>\n",
       "      <td>1.7752</td>\n",
       "      <td>1.757103</td>\n",
       "      <td>1.74378</td>\n",
       "      <td>1.728997</td>\n",
       "      <td>1.66828</td>\n",
       "      <td>1.662821</td>\n",
       "      <td>1.654527</td>\n",
       "      <td>1.638698</td>\n",
       "      <td>1.630503</td>\n",
       "      <td>1.629389</td>\n",
       "      <td>1.59688</td>\n",
       "      <td>1.588866</td>\n",
       "      <td>1.558329</td>\n",
       "      <td>1.52522</td>\n",
       "      <td>1.513808</td>\n",
       "      <td>1.512163</td>\n",
       "      <td>1.476213</td>\n",
       "      <td>1.462033</td>\n",
       "      <td>1.418929</td>\n",
       "      <td>1.396214</td>\n",
       "      <td>1.343253</td>\n",
       "      <td>1.288854</td>\n",
       "      <td>1.281238</td>\n",
       "      <td>1.275908</td>\n",
       "      <td>1.16557</td>\n",
       "      <td>1.143188</td>\n",
       "      <td>1.11098</td>\n",
       "      <td>1.036482</td>\n",
       "      <td>1.035149</td>\n",
       "      <td>0.995978</td>\n",
       "      <td>0.984765</td>\n",
       "      <td>0.976348</td>\n",
       "      <td>0.885169</td>\n",
       "      <td>0.848381</td>\n",
       "      <td>0.841537</td>\n",
       "      <td>0.834027</td>\n",
       "      <td>0.820547</td>\n",
       "      <td>0.80508</td>\n",
       "      <td>0.676841</td>\n",
       "      <td>0.629142</td>\n",
       "      <td>0.569557</td>\n",
       "      <td>0.508066</td>\n",
       "      <td>0.478187</td>\n",
       "      <td>0.420549</td>\n",
       "      <td>0.333369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>tf_Ġhey</td>\n",
       "      <td>ts_coleman_liau_index</td>\n",
       "      <td>ts_syllables_per_word</td>\n",
       "      <td>ts_polysyllable_frac</td>\n",
       "      <td>tf_Ġessential</td>\n",
       "      <td>ch_space_frac</td>\n",
       "      <td>tf_Ġessay</td>\n",
       "      <td>tf_Ġthank</td>\n",
       "      <td>tf_Ġbecause</td>\n",
       "      <td>tf_Ġsuccess</td>\n",
       "      <td>tf_Ġadditionally</td>\n",
       "      <td>tf_Ġsuper</td>\n",
       "      <td>tf_Ġachieving</td>\n",
       "      <td>tf_Ġgoals</td>\n",
       "      <td>tf_th</td>\n",
       "      <td>tf_Ġconfused</td>\n",
       "      <td>ts_smog_index</td>\n",
       "      <td>tf_Ġnt</td>\n",
       "      <td>tf_Ġgrader</td>\n",
       "      <td>tf_Ġvery</td>\n",
       "      <td>tf_Ġfirstly</td>\n",
       "      <td>tf_Ġwould</td>\n",
       "      <td>tf_Ġensures</td>\n",
       "      <td>tf_Ġvehicle</td>\n",
       "      <td>tf_Ġ8</td>\n",
       "      <td>ch_letter_frac</td>\n",
       "      <td>ch_punc_frac</td>\n",
       "      <td>tf_Ġsustainable</td>\n",
       "      <td>tf_Ġourselves</td>\n",
       "      <td>tf_Ġelectors</td>\n",
       "      <td>tf_Ġ3</td>\n",
       "      <td>tf_Ġand</td>\n",
       "      <td>tf_Ġultimately</td>\n",
       "      <td>tf_Ġconclusion</td>\n",
       "      <td>ts_monosyllable_frac</td>\n",
       "      <td>tf_Ġimportance</td>\n",
       "      <td>tf_Ġlike</td>\n",
       "      <td>tf_Ġaddress</td>\n",
       "      <td>tf_Ġimportant</td>\n",
       "      <td>tf_Ġvenus</td>\n",
       "      <td>tf_Ġfacial</td>\n",
       "      <td>tf_Ġdear</td>\n",
       "      <td>tf_Ġcomputer</td>\n",
       "      <td>tf_Ġperspectives</td>\n",
       "      <td>ts_lexicon_count</td>\n",
       "      <td>tf_Ġnasa</td>\n",
       "      <td>tf_Ġpotential</td>\n",
       "      <td>tf_Ġday</td>\n",
       "      <td>tf_Ġthen</td>\n",
       "      <td>tf_Ġchina</td>\n",
       "      <td>tf_Ġcool</td>\n",
       "      <td>ch_digit_frac</td>\n",
       "      <td>tf_Ġsense</td>\n",
       "      <td>tf_Ġsignificant</td>\n",
       "      <td>tf_Ġprotect</td>\n",
       "      <td>tf_Ġeurope</td>\n",
       "      <td>tf_Ġsystem</td>\n",
       "      <td>tf_Ġearth</td>\n",
       "      <td>tf_Ġcar</td>\n",
       "      <td>tf_Ġhumans</td>\n",
       "      <td>tf_Ġus</td>\n",
       "      <td>tf_Ġargue</td>\n",
       "      <td>tf_Ġalthough</td>\n",
       "      <td>ch_len</td>\n",
       "      <td>tf_Ġplus</td>\n",
       "      <td>tf_Ġparagraph</td>\n",
       "      <td>tf_Ġetc</td>\n",
       "      <td>tf_Ġskills</td>\n",
       "      <td>tf_Ġcars</td>\n",
       "      <td>tf_Ġpercent</td>\n",
       "      <td>tf_Ġreally</td>\n",
       "      <td>tf_Ġinformed</td>\n",
       "      <td>tf_Ġensure</td>\n",
       "      <td>tf_Ġextracurricular</td>\n",
       "      <td>tf_Ġwriting</td>\n",
       "      <td>tf_Ġactivity</td>\n",
       "      <td>tf_Ġhuman</td>\n",
       "      <td>tf_Ġprovide</td>\n",
       "      <td>tf_Ġprincipal</td>\n",
       "      <td>tf_Ġseagoing</td>\n",
       "      <td>tf_Ġdriving</td>\n",
       "      <td>tf_Ġthe</td>\n",
       "      <td>tf_Ġmost</td>\n",
       "      <td>tf_Ġphone</td>\n",
       "      <td>tf_Ġoverall</td>\n",
       "      <td>tf_Ġprobably</td>\n",
       "      <td>ts_words_per_sent</td>\n",
       "      <td>tf_Ġexperiences</td>\n",
       "      <td>tf_Ġlead</td>\n",
       "      <td>tf_Ġreduce</td>\n",
       "      <td>tf_Ġresources</td>\n",
       "      <td>tf_Ġalmost</td>\n",
       "      <td>tf_Ġhand</td>\n",
       "      <td>ts_sentence_count</td>\n",
       "      <td>tf_Ġdo</td>\n",
       "      <td>tf_Ġleast</td>\n",
       "      <td>tf_Ġeveryday</td>\n",
       "      <td>tf_Ġunique</td>\n",
       "      <td>tf_Ġtext</td>\n",
       "      <td>tf_Ġfurthermore</td>\n",
       "      <td>tf_Ġyou</td>\n",
       "      <td>ts_dale_chall_readability_score</td>\n",
       "      <td>tf_Ġschool</td>\n",
       "      <td>tf_Ġstate</td>\n",
       "      <td>tf_Ġmean</td>\n",
       "      <td>tf_Ġfair</td>\n",
       "      <td>tf_Ġconsider</td>\n",
       "      <td>tf_Ġhere</td>\n",
       "      <td>tf_Ġstates</td>\n",
       "      <td>tf_Ġreason</td>\n",
       "      <td>tf_Ġsecondly</td>\n",
       "      <td>tf_Ġservice</td>\n",
       "      <td>tf_Ġmany</td>\n",
       "      <td>tf_Ġsupport</td>\n",
       "      <td>tf_Ġgrade</td>\n",
       "      <td>tf_Ġcommunity</td>\n",
       "      <td>tf_Ġhealth</td>\n",
       "      <td>tf_Ġimpact</td>\n",
       "      <td>tf_Ġoffer</td>\n",
       "      <td>tf_Ġmy</td>\n",
       "      <td>tf_Ġwill</td>\n",
       "      <td>tf_Ġis</td>\n",
       "      <td>ts_mcalpine_eflaw</td>\n",
       "      <td>tf_Ġgo</td>\n",
       "      <td>tf_Ġlearn</td>\n",
       "      <td>tf_Ġmight</td>\n",
       "      <td>va_valence</td>\n",
       "      <td>tf_Ġeven</td>\n",
       "      <td>tf_Ġwhat</td>\n",
       "      <td>tf_Ġfinally</td>\n",
       "      <td>tf_Ġtrue</td>\n",
       "      <td>tf_Ġagree</td>\n",
       "      <td>tf_Ġso</td>\n",
       "      <td>tf_Ġtransportation</td>\n",
       "      <td>tf_Ġif</td>\n",
       "      <td>tf_Ġsincerely</td>\n",
       "      <td>tf_Ġthough</td>\n",
       "      <td>tf_Ġcould</td>\n",
       "      <td>tf_Ġtechnology</td>\n",
       "      <td>tf_Ġstudent</td>\n",
       "      <td>tf_Ġarticle</td>\n",
       "      <td>tf_Ġvehicles</td>\n",
       "      <td>tf_Ġknow</td>\n",
       "      <td>tf_Ġreasons</td>\n",
       "      <td>tf_Ġcreate</td>\n",
       "      <td>ch_upper_frac</td>\n",
       "      <td>tf_Ġstudents</td>\n",
       "      <td>tf_Ġdifficult</td>\n",
       "      <td>tf_Ġpoint</td>\n",
       "      <td>tf_Ġbenefits</td>\n",
       "      <td>tf_Ġafter</td>\n",
       "      <td>tf_Ġlet</td>\n",
       "      <td>tf_Ġbelieve</td>\n",
       "      <td>tf_Ġboth</td>\n",
       "      <td>tf_Ġi</td>\n",
       "      <td>tf_Ġclear</td>\n",
       "      <td>tf_Ġown</td>\n",
       "      <td>va_arousal</td>\n",
       "      <td>tf_Ġlimiting</td>\n",
       "      <td>tf_Ġam</td>\n",
       "      <td>tf_Ġat</td>\n",
       "      <td>ts_difficult_words</td>\n",
       "      <td>tf_Ġplanet</td>\n",
       "      <td>tf_Ġwe</td>\n",
       "      <td>tf_Ġthroughout</td>\n",
       "      <td>tf_Ġmatter</td>\n",
       "      <td>tf_Ġmeans</td>\n",
       "      <td>ts_syllable_count</td>\n",
       "      <td>tf_Ġshould</td>\n",
       "      <td>ts_spache_readability</td>\n",
       "      <td>tf_Ġit</td>\n",
       "      <td>tf_Ġfocus</td>\n",
       "      <td>tf_Ġunited</td>\n",
       "      <td>tf_Ġexplore</td>\n",
       "      <td>tf_Ġno</td>\n",
       "      <td>tf_Ġeverything</td>\n",
       "      <td>tf_Ġour</td>\n",
       "      <td>ts_flesch_kincaid_grade</td>\n",
       "      <td>tf_Ġget</td>\n",
       "      <td>ts_gunning_fog</td>\n",
       "      <td>tf_Ġsaid</td>\n",
       "      <td>tf_Ġkids</td>\n",
       "      <td>tf_Ġthey</td>\n",
       "      <td>ts_flesch_reading_ease</td>\n",
       "      <td>tf_Ġmay</td>\n",
       "      <td>tf_Ġdone</td>\n",
       "      <td>tf_Ġcan</td>\n",
       "      <td>tf_Ġbig</td>\n",
       "      <td>ts_syllables_per_sent</td>\n",
       "      <td>tf_Ġanother</td>\n",
       "      <td>va_dominance</td>\n",
       "      <td>tf_Ġwas</td>\n",
       "      <td>tf_Ġan</td>\n",
       "      <td>tf_Ġlast</td>\n",
       "      <td>tf_Ġoften</td>\n",
       "      <td>tf_Ġwhich</td>\n",
       "      <td>tf_Ġhard</td>\n",
       "      <td>tf_Ġhelping</td>\n",
       "      <td>tf_Ġits</td>\n",
       "      <td>tf_Ġgoing</td>\n",
       "      <td>tf_Ġthink</td>\n",
       "      <td>tf_Ġfriend</td>\n",
       "      <td>tf_Ġabout</td>\n",
       "      <td>tf_Ġpeople</td>\n",
       "      <td>tf_Ġname</td>\n",
       "      <td>tf_Ġme</td>\n",
       "      <td>tf_Ġexample</td>\n",
       "      <td>tf_Ġbut</td>\n",
       "      <td>tf_Ġyour</td>\n",
       "      <td>tf_Ġwhy</td>\n",
       "      <td>ts_automated_readability_index</td>\n",
       "      <td>tf_Ġwere</td>\n",
       "      <td>tf_Ġhome</td>\n",
       "      <td>tf_Ġwhile</td>\n",
       "      <td>tf_Ġfun</td>\n",
       "      <td>tf_Ġmuch</td>\n",
       "      <td>tf_Ġto</td>\n",
       "      <td>tf_Ġsports</td>\n",
       "      <td>tf_Ġevery</td>\n",
       "      <td>tf_Ġwho</td>\n",
       "      <td>tf_Ġfirst</td>\n",
       "      <td>tf_Ġeasier</td>\n",
       "      <td>tf_Ġsure</td>\n",
       "      <td>tf_Ġin</td>\n",
       "      <td>tf_Ġout</td>\n",
       "      <td>tf_Ġover</td>\n",
       "      <td>tf_Ġtake</td>\n",
       "      <td>tf_Ġnot</td>\n",
       "      <td>tf_Ġtwo</td>\n",
       "      <td>tf_Ġlives</td>\n",
       "      <td>tf_Ġthis</td>\n",
       "      <td>tf_Ġschools</td>\n",
       "      <td>tf_Ġmake</td>\n",
       "      <td>tf_Ġonce</td>\n",
       "      <td>tf_Ġworking</td>\n",
       "      <td>tf_Ġhis</td>\n",
       "      <td>tf_Ġthan</td>\n",
       "      <td>tf_Ġjust</td>\n",
       "      <td>tf_Ġwith</td>\n",
       "      <td>tf_Ġall</td>\n",
       "      <td>tf_Ġgood</td>\n",
       "      <td>tf_Ġhelps</td>\n",
       "      <td>tf_Ġnow</td>\n",
       "      <td>tf_Ġhowever</td>\n",
       "      <td>tf_Ġcause</td>\n",
       "      <td>tf_Ġstay</td>\n",
       "      <td>tf_Ġhaving</td>\n",
       "      <td>tf_Ġone</td>\n",
       "      <td>tf_Ġby</td>\n",
       "      <td>tf_Ġwhen</td>\n",
       "      <td>tf_Ġlearning</td>\n",
       "      <td>tf_Ġtime</td>\n",
       "      <td>tf_Ġface</td>\n",
       "      <td>tf_Ġtheir</td>\n",
       "      <td>tf_Ġinstead</td>\n",
       "      <td>tf_Ġbenefit</td>\n",
       "      <td>tf_Ġa</td>\n",
       "      <td>tf_Ġdown</td>\n",
       "      <td>tf_Ġfor</td>\n",
       "      <td>tf_Ġthere</td>\n",
       "      <td>tf_Ġusing</td>\n",
       "      <td>tf_Ġdoing</td>\n",
       "      <td>ts_linsear_write_formula</td>\n",
       "      <td>tf_Ġnumber</td>\n",
       "      <td>tf_Ġkeep</td>\n",
       "      <td>tf_Ġbecome</td>\n",
       "      <td>tf_Ġlife</td>\n",
       "      <td>tf_Ġperson</td>\n",
       "      <td>tf_Ġbeing</td>\n",
       "      <td>tf_Ġor</td>\n",
       "      <td>tf_Ġsame</td>\n",
       "      <td>tf_Ġhelp</td>\n",
       "      <td>tf_Ġare</td>\n",
       "      <td>tf_Ġmore</td>\n",
       "      <td>tf_Ġalso</td>\n",
       "      <td>tf_Ġbe</td>\n",
       "      <td>tf_Ġsome</td>\n",
       "      <td>tf_Ġput</td>\n",
       "      <td>tf_Ġas</td>\n",
       "      <td>tf_Ġthings</td>\n",
       "      <td>tf_Ġthat</td>\n",
       "      <td>tf_Ġhave</td>\n",
       "      <td>tf_Ġof</td>\n",
       "      <td>tf_Ġthem</td>\n",
       "      <td>ch_repeat_char_frac</td>\n",
       "      <td>tf_Ġon</td>\n",
       "      <td>tf_Ġfrom</td>\n",
       "      <td>tf_Ġbetter</td>\n",
       "      <td>tf_Ġduring</td>\n",
       "      <td>tf_Ġothers</td>\n",
       "      <td>tf_Ġonly</td>\n",
       "      <td>tf_Ġalways</td>\n",
       "      <td>tf_Ġdifferent</td>\n",
       "      <td>tf_Ġsee</td>\n",
       "      <td>tf_Ġother</td>\n",
       "      <td>tf_Ġnew</td>\n",
       "      <td>tf_Ġpart</td>\n",
       "      <td>tf_Ġthing</td>\n",
       "      <td>tf_Ġhow</td>\n",
       "      <td>tf_Ġpolicy</td>\n",
       "      <td>tf_Ġwant</td>\n",
       "      <td>tf_Ġidea</td>\n",
       "      <td>tf_Ġneed</td>\n",
       "      <td>tf_Ġway</td>\n",
       "      <td>tf_Ġup</td>\n",
       "      <td>tf_Ġwell</td>\n",
       "      <td>tf_Ġable</td>\n",
       "      <td>tf_Ġwork</td>\n",
       "      <td>tf_Ġaround</td>\n",
       "      <td>tf_Ġs</td>\n",
       "      <td>tf_Ġsuch</td>\n",
       "      <td>tf_Ġthese</td>\n",
       "      <td>tf_Ġfeel</td>\n",
       "      <td>tf_Ġfuture</td>\n",
       "      <td>tf_Ġsay</td>\n",
       "      <td>tf_Ġlot</td>\n",
       "      <td>tf_Ġfriends</td>\n",
       "      <td>tf_Ġsomeone</td>\n",
       "      <td>tf_Ġgreat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                      1                      2    \\\n",
       "importance  781.810486             490.538818             485.316528   \n",
       "feature        tf_Ġhey  ts_coleman_liau_index  ts_syllables_per_word   \n",
       "\n",
       "                             3              4              5           6    \\\n",
       "importance            336.407135     288.690765     288.211456  229.231964   \n",
       "feature     ts_polysyllable_frac  tf_Ġessential  ch_space_frac   tf_Ġessay   \n",
       "\n",
       "                   7            8            9                 10   \\\n",
       "importance  219.743591   209.669327   181.665131        179.183456   \n",
       "feature      tf_Ġthank  tf_Ġbecause  tf_Ġsuccess  tf_Ġadditionally   \n",
       "\n",
       "                   11             12          13          14            15   \\\n",
       "importance  169.901947     168.316895  167.481339  151.356659    143.653076   \n",
       "feature      tf_Ġsuper  tf_Ġachieving   tf_Ġgoals       tf_th  tf_Ġconfused   \n",
       "\n",
       "                      16          17          18         19           20   \\\n",
       "importance     140.939529  110.069252  101.857819  93.974632    90.115738   \n",
       "feature     ts_smog_index      tf_Ġnt  tf_Ġgrader   tf_Ġvery  tf_Ġfirstly   \n",
       "\n",
       "                  21           22           23         24              25   \\\n",
       "importance  88.624748    86.975922    85.581299  77.569267       77.131325   \n",
       "feature     tf_Ġwould  tf_Ġensures  tf_Ġvehicle      tf_Ġ8  ch_letter_frac   \n",
       "\n",
       "                     26               27             28            29   \\\n",
       "importance     75.604225        70.384636      69.825089     69.298241   \n",
       "feature     ch_punc_frac  tf_Ġsustainable  tf_Ġourselves  tf_Ġelectors   \n",
       "\n",
       "                  30         31              32              33   \\\n",
       "importance  67.570801  66.250443       63.203785       62.863422   \n",
       "feature         tf_Ġ3    tf_Ġand  tf_Ġultimately  tf_Ġconclusion   \n",
       "\n",
       "                             34              35         36           37   \\\n",
       "importance             61.277332       61.199062  57.946815    57.901653   \n",
       "feature     ts_monosyllable_frac  tf_Ġimportance   tf_Ġlike  tf_Ġaddress   \n",
       "\n",
       "                      38         39          40         41            42   \\\n",
       "importance      56.458355   54.44944   53.377113  52.523922     50.847752   \n",
       "feature     tf_Ġimportant  tf_Ġvenus  tf_Ġfacial   tf_Ġdear  tf_Ġcomputer   \n",
       "\n",
       "                         43                44         45             46   \\\n",
       "importance         50.176514         46.688572  46.042809       44.76157   \n",
       "feature     tf_Ġperspectives  ts_lexicon_count   tf_Ġnasa  tf_Ġpotential   \n",
       "\n",
       "                  47         48         49         50             51   \\\n",
       "importance  43.390869  42.235153  40.835976  40.318829      40.199787   \n",
       "feature       tf_Ġday   tf_Ġthen  tf_Ġchina   tf_Ġcool  ch_digit_frac   \n",
       "\n",
       "                  52               53           54          55          56   \\\n",
       "importance  39.128548        36.081169     36.04126   34.270901   33.954178   \n",
       "feature     tf_Ġsense  tf_Ġsignificant  tf_Ġprotect  tf_Ġeurope  tf_Ġsystem   \n",
       "\n",
       "                  57         58          59         60         61   \\\n",
       "importance   33.37429  32.947266   31.265629  30.823727  30.135227   \n",
       "feature     tf_Ġearth    tf_Ġcar  tf_Ġhumans     tf_Ġus  tf_Ġargue   \n",
       "\n",
       "                     62         63         64             65         66   \\\n",
       "importance     29.626429  29.362932  28.551178      27.447458  26.943707   \n",
       "feature     tf_Ġalthough     ch_len   tf_Ġplus  tf_Ġparagraph    tf_Ġetc   \n",
       "\n",
       "                   67         68           69          70            71   \\\n",
       "importance   26.039213  25.908745    25.699692    25.50363     24.424545   \n",
       "feature     tf_Ġskills   tf_Ġcars  tf_Ġpercent  tf_Ġreally  tf_Ġinformed   \n",
       "\n",
       "                   72                   73           74            75   \\\n",
       "importance   24.239599            24.071177    23.032135     22.710127   \n",
       "feature     tf_Ġensure  tf_Ġextracurricular  tf_Ġwriting  tf_Ġactivity   \n",
       "\n",
       "                  76           77             78            79           80   \\\n",
       "importance  22.611753    22.584135      21.534424     21.493031    21.450483   \n",
       "feature     tf_Ġhuman  tf_Ġprovide  tf_Ġprincipal  tf_Ġseagoing  tf_Ġdriving   \n",
       "\n",
       "                  81         82         83           84            85   \\\n",
       "importance  21.356768  20.933449  20.710167    20.395821     20.098389   \n",
       "feature       tf_Ġthe   tf_Ġmost  tf_Ġphone  tf_Ġoverall  tf_Ġprobably   \n",
       "\n",
       "                          86               87         88          89   \\\n",
       "importance          19.472715        19.420181  19.391479   18.932508   \n",
       "feature     ts_words_per_sent  tf_Ġexperiences   tf_Ġlead  tf_Ġreduce   \n",
       "\n",
       "                      90          91         92                 93   \\\n",
       "importance      18.800821   18.507572  18.358309          18.106339   \n",
       "feature     tf_Ġresources  tf_Ġalmost   tf_Ġhand  ts_sentence_count   \n",
       "\n",
       "                  94         95            96          97         98   \\\n",
       "importance  17.710629  17.690317     17.369865   17.249359  17.130758   \n",
       "feature        tf_Ġdo  tf_Ġleast  tf_Ġeveryday  tf_Ġunique   tf_Ġtext   \n",
       "\n",
       "                        99         100                              101  \\\n",
       "importance        16.952984  16.912823                        16.879992   \n",
       "feature     tf_Ġfurthermore    tf_Ġyou  ts_dale_chall_readability_score   \n",
       "\n",
       "                   102        103        104       105           106  \\\n",
       "importance   16.801064  16.675583  16.646465  16.53372     16.395014   \n",
       "feature     tf_Ġschool  tf_Ġstate   tf_Ġmean  tf_Ġfair  tf_Ġconsider   \n",
       "\n",
       "                  107         108         109           110          111  \\\n",
       "importance  16.263538   16.058931   15.312901     14.979809      14.0781   \n",
       "feature      tf_Ġhere  tf_Ġstates  tf_Ġreason  tf_Ġsecondly  tf_Ġservice   \n",
       "\n",
       "                 112          113        114            115         116  \\\n",
       "importance  13.79497    13.216605  13.105409      13.085265   12.985317   \n",
       "feature     tf_Ġmany  tf_Ġsupport  tf_Ġgrade  tf_Ġcommunity  tf_Ġhealth   \n",
       "\n",
       "                   117        118        119        120        121  \\\n",
       "importance   12.907841  12.708452  12.667187  12.591174  12.368817   \n",
       "feature     tf_Ġimpact  tf_Ġoffer     tf_Ġmy   tf_Ġwill     tf_Ġis   \n",
       "\n",
       "                          122        123        124        125         126  \\\n",
       "importance          12.266745  12.248855   12.22839  12.214986   12.189629   \n",
       "feature     ts_mcalpine_eflaw     tf_Ġgo  tf_Ġlearn  tf_Ġmight  va_valence   \n",
       "\n",
       "                  127        128          129        130        131  \\\n",
       "importance  12.023846  11.685711     11.51645  11.498635  11.412957   \n",
       "feature      tf_Ġeven   tf_Ġwhat  tf_Ġfinally   tf_Ġtrue  tf_Ġagree   \n",
       "\n",
       "                  132                 133        134            135  \\\n",
       "importance  11.209677           10.870028  10.845504        10.8053   \n",
       "feature        tf_Ġso  tf_Ġtransportation     tf_Ġif  tf_Ġsincerely   \n",
       "\n",
       "                   136        137             138          139          140  \\\n",
       "importance   10.681151  10.634077       10.436765    10.416463    10.245605   \n",
       "feature     tf_Ġthough  tf_Ġcould  tf_Ġtechnology  tf_Ġstudent  tf_Ġarticle   \n",
       "\n",
       "                     141       142          143         144            145  \\\n",
       "importance        9.8927  9.564544     9.530143    9.510941       9.464931   \n",
       "feature     tf_Ġvehicles  tf_Ġknow  tf_Ġreasons  tf_Ġcreate  ch_upper_frac   \n",
       "\n",
       "                     146            147        148           149        150  \\\n",
       "importance      9.168464       9.160788    9.05891      9.055192   8.884005   \n",
       "feature     tf_Ġstudents  tf_Ġdifficult  tf_Ġpoint  tf_Ġbenefits  tf_Ġafter   \n",
       "\n",
       "                 151          152       153      154        155       156  \\\n",
       "importance  8.883018     8.678984  8.647542  8.55966   8.511078  8.084966   \n",
       "feature      tf_Ġlet  tf_Ġbelieve  tf_Ġboth    tf_Ġi  tf_Ġclear   tf_Ġown   \n",
       "\n",
       "                   157           158       159      160                 161  \\\n",
       "importance    8.036461      7.956953  7.909729  7.55541            7.534116   \n",
       "feature     va_arousal  tf_Ġlimiting    tf_Ġam   tf_Ġat  ts_difficult_words   \n",
       "\n",
       "                   162       163             164         165        166  \\\n",
       "importance    7.440822  7.436173        7.433044    7.310189   7.203867   \n",
       "feature     tf_Ġplanet    tf_Ġwe  tf_Ġthroughout  tf_Ġmatter  tf_Ġmeans   \n",
       "\n",
       "                          167         168                    169       170  \\\n",
       "importance           7.152648    7.146918                7.11026  7.101671   \n",
       "feature     ts_syllable_count  tf_Ġshould  ts_spache_readability    tf_Ġit   \n",
       "\n",
       "                  171         172          173       174             175  \\\n",
       "importance   6.941996    6.941086     6.813098  6.753841        6.731386   \n",
       "feature     tf_Ġfocus  tf_Ġunited  tf_Ġexplore    tf_Ġno  tf_Ġeverything   \n",
       "\n",
       "                 176                      177       178             179  \\\n",
       "importance  6.682386                 6.637693  6.609685        6.514729   \n",
       "feature      tf_Ġour  ts_flesch_kincaid_grade   tf_Ġget  ts_gunning_fog   \n",
       "\n",
       "                 180       181       182                     183       184  \\\n",
       "importance  6.467379  6.006093  5.971101                5.930752  5.877871   \n",
       "feature     tf_Ġsaid  tf_Ġkids  tf_Ġthey  ts_flesch_reading_ease   tf_Ġmay   \n",
       "\n",
       "                 185       186      187                    188          189  \\\n",
       "importance  5.752261  5.685339  5.64645               5.622975     5.396545   \n",
       "feature     tf_Ġdone   tf_Ġcan  tf_Ġbig  ts_syllables_per_sent  tf_Ġanother   \n",
       "\n",
       "                     190       191       192       193        194        195  \\\n",
       "importance      5.314053  5.280446  5.232251  5.213174   5.166775   5.094082   \n",
       "feature     va_dominance   tf_Ġwas    tf_Ġan  tf_Ġlast  tf_Ġoften  tf_Ġwhich   \n",
       "\n",
       "                 196          197       198        199        200         201  \\\n",
       "importance  5.069883     5.025868  4.883653   4.853292   4.834744    4.783371   \n",
       "feature     tf_Ġhard  tf_Ġhelping   tf_Ġits  tf_Ġgoing  tf_Ġthink  tf_Ġfriend   \n",
       "\n",
       "                  202         203       204       205          206       207  \\\n",
       "importance   4.732041    4.612059  4.603532  4.580497     4.535528  4.528878   \n",
       "feature     tf_Ġabout  tf_Ġpeople  tf_Ġname    tf_Ġme  tf_Ġexample   tf_Ġbut   \n",
       "\n",
       "                 208       209                             210       211  \\\n",
       "importance  4.481597  4.420849                        4.358688  4.354087   \n",
       "feature     tf_Ġyour   tf_Ġwhy  ts_automated_readability_index  tf_Ġwere   \n",
       "\n",
       "                 212        213       214       215       216         217  \\\n",
       "importance  4.349886   4.252539  4.079772   4.05571  3.973468    3.923386   \n",
       "feature     tf_Ġhome  tf_Ġwhile   tf_Ġfun  tf_Ġmuch    tf_Ġto  tf_Ġsports   \n",
       "\n",
       "                  218       219        220         221       222       223  \\\n",
       "importance   3.863719  3.863282   3.832214     3.77792  3.740831  3.656284   \n",
       "feature     tf_Ġevery   tf_Ġwho  tf_Ġfirst  tf_Ġeasier  tf_Ġsure    tf_Ġin   \n",
       "\n",
       "                 224       225       226       227       228        229  \\\n",
       "importance  3.606041  3.538441  3.515561  3.495106  3.396851   3.372038   \n",
       "feature      tf_Ġout  tf_Ġover  tf_Ġtake   tf_Ġnot   tf_Ġtwo  tf_Ġlives   \n",
       "\n",
       "                 230          231       232       233          234      235  \\\n",
       "importance  3.335905     3.179139  3.097436  3.039652      3.02588  3.02353   \n",
       "feature     tf_Ġthis  tf_Ġschools  tf_Ġmake  tf_Ġonce  tf_Ġworking  tf_Ġhis   \n",
       "\n",
       "                 236       237       238       239       240        241  \\\n",
       "importance  3.010557  2.998088   2.99721  2.875458  2.818633   2.782501   \n",
       "feature     tf_Ġthan  tf_Ġjust  tf_Ġwith   tf_Ġall  tf_Ġgood  tf_Ġhelps   \n",
       "\n",
       "                 242          243        244       245         246       247  \\\n",
       "importance  2.717593     2.684284   2.676867  2.652729    2.641006  2.593753   \n",
       "feature      tf_Ġnow  tf_Ġhowever  tf_Ġcause  tf_Ġstay  tf_Ġhaving   tf_Ġone   \n",
       "\n",
       "                 248       249           250       251       252        253  \\\n",
       "importance  2.583044  2.550439      2.528988  2.523669  2.436218   2.430205   \n",
       "feature       tf_Ġby  tf_Ġwhen  tf_Ġlearning  tf_Ġtime  tf_Ġface  tf_Ġtheir   \n",
       "\n",
       "                    254          255       256       257       258        259  \\\n",
       "importance     2.418217     2.374122  2.238956  2.226804  2.208097   2.202519   \n",
       "feature     tf_Ġinstead  tf_Ġbenefit     tf_Ġa  tf_Ġdown   tf_Ġfor  tf_Ġthere   \n",
       "\n",
       "                  260        261                       262         263  \\\n",
       "importance   2.190012   2.185219                  2.170147    2.127258   \n",
       "feature     tf_Ġusing  tf_Ġdoing  ts_linsear_write_formula  tf_Ġnumber   \n",
       "\n",
       "                 264         265       266         267        268       269  \\\n",
       "importance   2.09442     2.03263  2.009032    2.008704   1.952991  1.919455   \n",
       "feature     tf_Ġkeep  tf_Ġbecome  tf_Ġlife  tf_Ġperson  tf_Ġbeing    tf_Ġor   \n",
       "\n",
       "                 270       271       272       273       274       275  \\\n",
       "importance  1.857847  1.850523  1.818397  1.776517    1.7752  1.757103   \n",
       "feature     tf_Ġsame  tf_Ġhelp   tf_Ġare  tf_Ġmore  tf_Ġalso    tf_Ġbe   \n",
       "\n",
       "                 276       277      278         279       280       281  \\\n",
       "importance   1.74378  1.728997  1.66828    1.662821  1.654527  1.638698   \n",
       "feature     tf_Ġsome   tf_Ġput   tf_Ġas  tf_Ġthings  tf_Ġthat  tf_Ġhave   \n",
       "\n",
       "                 282       283                  284       285       286  \\\n",
       "importance  1.630503  1.629389              1.59688  1.588866  1.558329   \n",
       "feature       tf_Ġof  tf_Ġthem  ch_repeat_char_frac    tf_Ġon  tf_Ġfrom   \n",
       "\n",
       "                   287         288         289       290         291  \\\n",
       "importance     1.52522    1.513808    1.512163  1.476213    1.462033   \n",
       "feature     tf_Ġbetter  tf_Ġduring  tf_Ġothers  tf_Ġonly  tf_Ġalways   \n",
       "\n",
       "                      292       293        294       295       296        297  \\\n",
       "importance       1.418929  1.396214   1.343253  1.288854  1.281238   1.275908   \n",
       "feature     tf_Ġdifferent   tf_Ġsee  tf_Ġother   tf_Ġnew  tf_Ġpart  tf_Ġthing   \n",
       "\n",
       "                298         299       300       301       302       303  \\\n",
       "importance  1.16557    1.143188   1.11098  1.036482  1.035149  0.995978   \n",
       "feature     tf_Ġhow  tf_Ġpolicy  tf_Ġwant  tf_Ġidea  tf_Ġneed   tf_Ġway   \n",
       "\n",
       "                 304       305       306       307         308       309  \\\n",
       "importance  0.984765  0.976348  0.885169  0.848381    0.841537  0.834027   \n",
       "feature       tf_Ġup  tf_Ġwell  tf_Ġable  tf_Ġwork  tf_Ġaround     tf_Ġs   \n",
       "\n",
       "                 310        311       312         313       314       315  \\\n",
       "importance  0.820547    0.80508  0.676841    0.629142  0.569557  0.508066   \n",
       "feature     tf_Ġsuch  tf_Ġthese  tf_Ġfeel  tf_Ġfuture   tf_Ġsay   tf_Ġlot   \n",
       "\n",
       "                    316          317        318  \n",
       "importance     0.478187     0.420549   0.333369  \n",
       "feature     tf_Ġfriends  tf_Ġsomeone  tf_Ġgreat  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores = model.get_score(importance_type=\"gain\")\n",
    "assert len(scores)!=0\n",
    "rows = []\n",
    "for feature, score in scores.items():\n",
    "    rows.append({'importance': score, 'feature': feature})\n",
    "idf = pd.DataFrame.from_records(rows)\n",
    "idf = idf.sort_values([\"importance\"], ascending=False, ignore_index=True)\n",
    "fp = f\"{job_dir}/importance.csv\"\n",
    "idf.to_csv(fp, index=True)\n",
    "print(f\"Saved {fp}\")\n",
    "idf.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a994ecf2-2058-4117-923f-bda3a05f83f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:16:10.125440\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
