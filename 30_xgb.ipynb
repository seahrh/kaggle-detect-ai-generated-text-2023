{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062a9473-ec3c-4f1c-80de-66912972bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from typing import List, Dict, Union, Tuple, NamedTuple\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafd5a38-0166-47b6-aed4-7ae66bd7bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "job_dir = f\"models/xgb/{ts}\"\n",
    "pathlib.Path(job_dir).mkdir(parents=True, exist_ok=True)\n",
    "num_boost_round: int = 100\n",
    "lr: Tuple[float, float] = (1e-3, 1e-3)\n",
    "feature_fraction: Tuple[float, float] = (1, 1)\n",
    "min_data_in_leaf: Tuple[int, int] = (20, 20)\n",
    "objective: str = \"binary:logistic\"\n",
    "n_trials: int = 1\n",
    "label = \"generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e822fad3-d0a9-4094-9efb-60cde058d454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39120 entries, 0 to 39119\n",
      "Data columns (total 41 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   essay_id                         39120 non-null  int32  \n",
      " 1   generated                        39120 non-null  int8   \n",
      " 2   source                           39120 non-null  object \n",
      " 3   prompt                           39120 non-null  object \n",
      " 4   text                             39120 non-null  object \n",
      " 5   text_bsc                         39120 non-null  object \n",
      " 6   text_bow                         39120 non-null  object \n",
      " 7   text_bow_len                     39120 non-null  int16  \n",
      " 8   prompt_bsc                       39120 non-null  object \n",
      " 9   prompt_bow                       39120 non-null  object \n",
      " 10  prompt_bow_len                   39120 non-null  int16  \n",
      " 11  white_sim                        39120 non-null  float32\n",
      " 12  ch_len                           39120 non-null  int32  \n",
      " 13  ch_digit_frac                    39120 non-null  float32\n",
      " 14  ch_letter_frac                   39120 non-null  float32\n",
      " 15  ch_space_frac                    39120 non-null  float32\n",
      " 16  ch_punc_frac                     39120 non-null  float32\n",
      " 17  ch_upper_frac                    39120 non-null  float32\n",
      " 18  ch_repeat_char_frac              39120 non-null  float32\n",
      " 19  ts_syllable_count                39120 non-null  int32  \n",
      " 20  ts_lexicon_count                 39120 non-null  int32  \n",
      " 21  ts_sentence_count                39120 non-null  int32  \n",
      " 22  ts_syllables_per_word            39120 non-null  float32\n",
      " 23  ts_syllables_per_sent            39120 non-null  float32\n",
      " 24  ts_words_per_sent                39120 non-null  float32\n",
      " 25  ts_polysyllable_frac             39120 non-null  float32\n",
      " 26  ts_monosyllable_frac             39120 non-null  float32\n",
      " 27  ts_flesch_reading_ease           39120 non-null  float32\n",
      " 28  ts_flesch_kincaid_grade          39120 non-null  float32\n",
      " 29  ts_gunning_fog                   39120 non-null  float32\n",
      " 30  ts_smog_index                    39120 non-null  float32\n",
      " 31  ts_automated_readability_index   39120 non-null  float32\n",
      " 32  ts_coleman_liau_index            39120 non-null  float32\n",
      " 33  ts_linsear_write_formula         39120 non-null  float32\n",
      " 34  ts_dale_chall_readability_score  39120 non-null  float32\n",
      " 35  ts_difficult_words               39120 non-null  float32\n",
      " 36  ts_spache_readability            39120 non-null  float32\n",
      " 37  ts_mcalpine_eflaw                39120 non-null  float32\n",
      " 38  va_valence                       39120 non-null  float32\n",
      " 39  va_arousal                       39120 non-null  float32\n",
      " 40  va_dominance                     39120 non-null  float32\n",
      "dtypes: float32(26), int16(2), int32(5), int8(1), object(7)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/features.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb8e82b-a582-4d2a-88e1-d4a4c85a1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 features\n",
      "['ch_digit_frac', 'ch_len', 'ch_letter_frac', 'ch_punc_frac', 'ch_repeat_char_frac', 'ch_space_frac', 'ch_upper_frac', 'ts_automated_readability_index', 'ts_coleman_liau_index', 'ts_dale_chall_readability_score', 'ts_difficult_words', 'ts_flesch_kincaid_grade', 'ts_flesch_reading_ease', 'ts_gunning_fog', 'ts_lexicon_count', 'ts_linsear_write_formula', 'ts_mcalpine_eflaw', 'ts_monosyllable_frac', 'ts_polysyllable_frac', 'ts_sentence_count', 'ts_smog_index', 'ts_spache_readability', 'ts_syllable_count', 'ts_syllables_per_sent', 'ts_syllables_per_word', 'ts_words_per_sent', 'va_arousal', 'va_dominance', 'va_valence']\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "prefixes = [\"ch_\", \"ts_\", \"va_\"]\n",
    "for col in df.columns:\n",
    "    for prefix in prefixes:\n",
    "        if col.startswith(prefix):\n",
    "            features.append(col)\n",
    "features.sort()\n",
    "print(f\"{len(features)} features\\n{features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fd2b91-247a-4891-9859-478bb1d42583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val%=0.0293, len(tra)=37,974, len(val)=1,146\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(tra[features], tra[label], test_size=0.2)\n",
    "\n",
    "tra = df[df[\"white_sim\"]>=0.45]\n",
    "val = df[df[\"white_sim\"]<0.45]\n",
    "t = len(tra)\n",
    "v = len(val)\n",
    "n = t+v\n",
    "print(f\"val%={v/n:.4f}, len(tra)={t:,}, len(val)={v:,}\")\n",
    "dtrain = xgb.DMatrix(tra[features], tra[label], enable_categorical=False)\n",
    "dval = xgb.DMatrix(val[features], val[label], enable_categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df30c12e-601b-4dcb-8ab9-90f3beb13b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.51329\tval-logloss:1.07530\n",
      "[40]\ttrain-logloss:0.18278\tval-logloss:0.41648\n",
      "[80]\ttrain-logloss:0.12897\tval-logloss:0.31842\n",
      "[120]\ttrain-logloss:0.11198\tval-logloss:0.28780\n",
      "[160]\ttrain-logloss:0.10216\tval-logloss:0.27748\n",
      "[200]\ttrain-logloss:0.09625\tval-logloss:0.27143\n",
      "[240]\ttrain-logloss:0.09088\tval-logloss:0.26826\n",
      "[280]\ttrain-logloss:0.08660\tval-logloss:0.26555\n",
      "[320]\ttrain-logloss:0.08324\tval-logloss:0.26334\n",
      "[360]\ttrain-logloss:0.07991\tval-logloss:0.26288\n",
      "[400]\ttrain-logloss:0.07712\tval-logloss:0.26216\n",
      "[437]\ttrain-logloss:0.07470\tval-logloss:0.26249\n",
      "best score 0.26194 at iteration 398\n",
      "CPU times: user 4.93 s, sys: 4.58 s, total: 9.51 s\n",
      "Wall time: 715 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.train(\n",
    "   params={\n",
    "       \"objective\": objective,\n",
    "       \"learning_rate\": 5e-2,\n",
    "       \"min_child_weight\": 20,\n",
    "       \"colsample_bytree\": 0.5,\n",
    "       \"max_depth\": 6,\n",
    "   },\n",
    "   dtrain=dtrain,\n",
    "   num_boost_round=1000,\n",
    "   evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "   verbose_eval=40,\n",
    "   early_stopping_rounds=40,\n",
    ")\n",
    "print(f\"best score {model.best_score:.5f} at iteration {model.best_iteration}\")\n",
    "model.save_model(f\"{job_dir}/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6da2370-9acb-42fa-894f-c4da29da6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.9748\n",
      "y_pred=(1146,)\n",
      "[0.82103187 0.9493867  0.74025995 0.6455425  0.9989002 ]\n",
      "CPU times: user 15.6 ms, sys: 9.14 ms, total: 24.7 ms\n",
      "Wall time: 2.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_true = val[label].tolist()\n",
    "y_pred = model.predict(data=dval, iteration_range=(0, model.best_iteration+1))\n",
    "auc = roc_auc_score(y_true, y_pred, average=\"macro\")\n",
    "print(f\"auc={auc:.4f}\")\n",
    "print(f\"y_pred={y_pred.shape}\\n{y_pred[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f793a39d-7bce-4472-aef3-bacde89ee929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models/xgb/20240119_123616/importance.csv\n",
      "CPU times: user 7.26 ms, sys: 17.7 ms, total: 24.9 ms\n",
      "Wall time: 2.2 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>276.287354</td>\n",
       "      <td>151.579041</td>\n",
       "      <td>76.50148</td>\n",
       "      <td>56.02932</td>\n",
       "      <td>54.844772</td>\n",
       "      <td>41.199722</td>\n",
       "      <td>39.865898</td>\n",
       "      <td>39.26535</td>\n",
       "      <td>37.546597</td>\n",
       "      <td>32.953194</td>\n",
       "      <td>27.869537</td>\n",
       "      <td>27.72086</td>\n",
       "      <td>24.907961</td>\n",
       "      <td>23.786636</td>\n",
       "      <td>22.43483</td>\n",
       "      <td>21.892349</td>\n",
       "      <td>21.785358</td>\n",
       "      <td>16.454042</td>\n",
       "      <td>14.276403</td>\n",
       "      <td>14.098075</td>\n",
       "      <td>13.76993</td>\n",
       "      <td>12.711823</td>\n",
       "      <td>10.957132</td>\n",
       "      <td>10.487169</td>\n",
       "      <td>9.170912</td>\n",
       "      <td>8.902815</td>\n",
       "      <td>8.239889</td>\n",
       "      <td>7.005947</td>\n",
       "      <td>6.044771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>ts_syllables_per_word</td>\n",
       "      <td>ts_polysyllable_frac</td>\n",
       "      <td>ch_punc_frac</td>\n",
       "      <td>ch_space_frac</td>\n",
       "      <td>ch_digit_frac</td>\n",
       "      <td>ts_lexicon_count</td>\n",
       "      <td>ts_sentence_count</td>\n",
       "      <td>ts_smog_index</td>\n",
       "      <td>ch_letter_frac</td>\n",
       "      <td>ts_syllable_count</td>\n",
       "      <td>ts_coleman_liau_index</td>\n",
       "      <td>ch_len</td>\n",
       "      <td>ts_difficult_words</td>\n",
       "      <td>ts_words_per_sent</td>\n",
       "      <td>ts_monosyllable_frac</td>\n",
       "      <td>ch_upper_frac</td>\n",
       "      <td>va_valence</td>\n",
       "      <td>ts_spache_readability</td>\n",
       "      <td>va_arousal</td>\n",
       "      <td>ts_gunning_fog</td>\n",
       "      <td>ts_dale_chall_readability_score</td>\n",
       "      <td>ts_mcalpine_eflaw</td>\n",
       "      <td>ts_syllables_per_sent</td>\n",
       "      <td>va_dominance</td>\n",
       "      <td>ch_repeat_char_frac</td>\n",
       "      <td>ts_automated_readability_index</td>\n",
       "      <td>ts_flesch_kincaid_grade</td>\n",
       "      <td>ts_flesch_reading_ease</td>\n",
       "      <td>ts_linsear_write_formula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                     1             2   \\\n",
       "importance             276.287354            151.579041      76.50148   \n",
       "feature     ts_syllables_per_word  ts_polysyllable_frac  ch_punc_frac   \n",
       "\n",
       "                       3              4                 5                  6   \\\n",
       "importance       56.02932      54.844772         41.199722          39.865898   \n",
       "feature     ch_space_frac  ch_digit_frac  ts_lexicon_count  ts_sentence_count   \n",
       "\n",
       "                       7               8                  9   \\\n",
       "importance       39.26535       37.546597          32.953194   \n",
       "feature     ts_smog_index  ch_letter_frac  ts_syllable_count   \n",
       "\n",
       "                               10        11                  12  \\\n",
       "importance              27.869537  27.72086           24.907961   \n",
       "feature     ts_coleman_liau_index    ch_len  ts_difficult_words   \n",
       "\n",
       "                           13                    14             15  \\\n",
       "importance          23.786636              22.43483      21.892349   \n",
       "feature     ts_words_per_sent  ts_monosyllable_frac  ch_upper_frac   \n",
       "\n",
       "                    16                     17          18              19  \\\n",
       "importance   21.785358              16.454042   14.276403       14.098075   \n",
       "feature     va_valence  ts_spache_readability  va_arousal  ts_gunning_fog   \n",
       "\n",
       "                                         20                 21  \\\n",
       "importance                         13.76993          12.711823   \n",
       "feature     ts_dale_chall_readability_score  ts_mcalpine_eflaw   \n",
       "\n",
       "                               22            23                   24  \\\n",
       "importance              10.957132     10.487169             9.170912   \n",
       "feature     ts_syllables_per_sent  va_dominance  ch_repeat_char_frac   \n",
       "\n",
       "                                        25                       26  \\\n",
       "importance                        8.902815                 8.239889   \n",
       "feature     ts_automated_readability_index  ts_flesch_kincaid_grade   \n",
       "\n",
       "                                27                        28  \n",
       "importance                7.005947                  6.044771  \n",
       "feature     ts_flesch_reading_ease  ts_linsear_write_formula  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores = model.get_score(importance_type=\"gain\")\n",
    "assert len(scores)!=0\n",
    "rows = []\n",
    "for feature, score in scores.items():\n",
    "    rows.append({'importance': score, 'feature': feature})\n",
    "idf = pd.DataFrame.from_records(rows)\n",
    "idf = idf.sort_values([\"importance\"], ascending=False, ignore_index=True)\n",
    "fp = f\"{job_dir}/importance.csv\"\n",
    "idf.to_csv(fp, index=True)\n",
    "print(f\"Saved {fp}\")\n",
    "idf.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a994ecf2-2058-4117-923f-bda3a05f83f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:00.949201\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
