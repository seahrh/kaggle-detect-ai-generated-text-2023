{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062a9473-ec3c-4f1c-80de-66912972bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from typing import List, Dict, Union, Tuple, NamedTuple\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafd5a38-0166-47b6-aed4-7ae66bd7bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "job_dir = f\"models/xgb/{ts}\"\n",
    "pathlib.Path(job_dir).mkdir(parents=True, exist_ok=True)\n",
    "num_boost_round: int = 100\n",
    "lr: Tuple[float, float] = (1e-3, 1e-3)\n",
    "feature_fraction: Tuple[float, float] = (1, 1)\n",
    "min_data_in_leaf: Tuple[int, int] = (20, 20)\n",
    "objective: str = \"binary:logistic\"\n",
    "n_trials: int = 1\n",
    "label = \"generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e822fad3-d0a9-4094-9efb-60cde058d454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43529 entries, 0 to 43528\n",
      "Columns: 29835 entries, essay_id to tf_Ġzygomatic\n",
      "dtypes: float32(29820), int16(2), int32(5), int8(1), object(7)\n",
      "memory usage: 4.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"input/features.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb8e82b-a582-4d2a-88e1-d4a4c85a1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29823 features\n",
      "['ch_digit_frac', 'ch_len', 'ch_letter_frac', 'ch_punc_frac', 'ch_repeat_char_frac', 'ch_space_frac', 'ch_upper_frac', 'tf_0', 'tf_00', 'tf_000', 'tf_03', 'tf_1', 'tf_10', 'tf_11', 'tf_12', 'tf_13', 'tf_14', 'tf_15', 'tf_16', 'tf_17', 'tf_18', 'tf_19', 'tf_1990', 'tf_2', 'tf_20', 'tf_200', 'tf_21', 'tf_23', 'tf_24', 'tf_25', 'tf_27', 'tf_28', 'tf_3', 'tf_30', 'tf_31', 'tf_32', 'tf_33', 'tf_34', 'tf_38', 'tf_39', 'tf_4', 'tf_40', 'tf_41', 'tf_43', 'tf_45', 'tf_5', 'tf_50', 'tf_538', 'tf_58', 'tf_6', 'tf_60', 'tf_62', 'tf_7', 'tf_70', 'tf_74', 'tf_76', 'tf_79', 'tf_8', 'tf_87', 'tf_9', 'tf_90', 'tf_a', 'tf_aa', 'tf_aae', 'tf_aage', 'tf_aaion', 'tf_ab', 'tf_aban', 'tf_abe', 'tf_abel', 'tf_aber', 'tf_abet', 'tf_abeth', 'tf_abil', 'tf_abilites', 'tf_abilitie', 'tf_abilities', 'tf_ability', 'tf_abill', 'tf_abilty', 'tf_abitable', 'tf_abital', 'tf_abl', 'tf_able', 'tf_abled', 'tf_ables', 'tf_abling', 'tf_ablished', 'tf_ablities', 'tf_ablity', 'tf_ably', 'tf_about', 'tf_abra', 'tf_abraeus', 'tf_abs', 'tf_abul', 'tf_aby', 'tf_ac', 'tf_aca', 'tf_acary']\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "prefixes = [\"ch_\", \"ws_\", \"ts_\", \"va_\", \"tf_\"]\n",
    "for col in df.columns:\n",
    "    for prefix in prefixes:\n",
    "        if col.startswith(prefix):\n",
    "            features.append(col)\n",
    "features.sort()\n",
    "print(f\"{len(features)} features\\n{features[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fd2b91-247a-4891-9859-478bb1d42583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val%=0.0214, len(tra)=42,596, len(val)=933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>793</td>\n",
       "      <td>0.849946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>0.150054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count   percent\n",
       "generated                 \n",
       "1            793  0.849946\n",
       "0            140  0.150054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(tra[features], tra[label], test_size=0.2)\n",
    "\n",
    "tra = df[df[\"white_sim\"]>=0.45]\n",
    "val = df[df[\"white_sim\"]<0.45]\n",
    "t = len(tra)\n",
    "v = len(val)\n",
    "n = t+v\n",
    "print(f\"val%={v/n:.4f}, len(tra)={t:,}, len(val)={v:,}\")\n",
    "dtrain = xgb.DMatrix(tra[features], tra[label], enable_categorical=False)\n",
    "dval = xgb.DMatrix(val[features], val[label], enable_categorical=False)\n",
    "pdx.value_counts(val[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df30c12e-601b-4dcb-8ab9-90f3beb13b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.58618\tval-logloss:0.97015\n",
      "[40]\ttrain-logloss:0.14982\tval-logloss:0.36515\n",
      "[80]\ttrain-logloss:0.07517\tval-logloss:0.23699\n",
      "[120]\ttrain-logloss:0.04963\tval-logloss:0.18333\n",
      "[160]\ttrain-logloss:0.03766\tval-logloss:0.15579\n",
      "[200]\ttrain-logloss:0.03024\tval-logloss:0.13848\n",
      "[240]\ttrain-logloss:0.02504\tval-logloss:0.12711\n",
      "[280]\ttrain-logloss:0.02149\tval-logloss:0.12077\n",
      "[320]\ttrain-logloss:0.01872\tval-logloss:0.11470\n",
      "[360]\ttrain-logloss:0.01647\tval-logloss:0.11067\n",
      "[400]\ttrain-logloss:0.01476\tval-logloss:0.10653\n",
      "[440]\ttrain-logloss:0.01331\tval-logloss:0.10451\n",
      "[480]\ttrain-logloss:0.01210\tval-logloss:0.10301\n",
      "[520]\ttrain-logloss:0.01103\tval-logloss:0.10151\n",
      "[560]\ttrain-logloss:0.01010\tval-logloss:0.10100\n",
      "[600]\ttrain-logloss:0.00932\tval-logloss:0.10048\n",
      "[640]\ttrain-logloss:0.00865\tval-logloss:0.09999\n",
      "[680]\ttrain-logloss:0.00805\tval-logloss:0.09904\n",
      "[720]\ttrain-logloss:0.00753\tval-logloss:0.09878\n",
      "[760]\ttrain-logloss:0.00707\tval-logloss:0.09817\n",
      "[800]\ttrain-logloss:0.00666\tval-logloss:0.09777\n",
      "[840]\ttrain-logloss:0.00630\tval-logloss:0.09776\n",
      "[880]\ttrain-logloss:0.00599\tval-logloss:0.09761\n",
      "[920]\ttrain-logloss:0.00570\tval-logloss:0.09724\n",
      "[960]\ttrain-logloss:0.00546\tval-logloss:0.09747\n",
      "[1000]\ttrain-logloss:0.00522\tval-logloss:0.09742\n",
      "[1040]\ttrain-logloss:0.00503\tval-logloss:0.09735\n",
      "[1080]\ttrain-logloss:0.00485\tval-logloss:0.09741\n",
      "[1083]\ttrain-logloss:0.00484\tval-logloss:0.09753\n",
      "best score 0.09708 at iteration 983\n",
      "CPU times: user 2h 52min 34s, sys: 35min 55s, total: 3h 28min 30s\n",
      "Wall time: 17min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.train(\n",
    "   params={\n",
    "       \"objective\": objective,\n",
    "       \"learning_rate\": 5e-2,\n",
    "       \"min_child_weight\": 20,\n",
    "       \"colsample_bytree\": 0.5,\n",
    "       \"max_depth\": 6,\n",
    "   },\n",
    "   dtrain=dtrain,\n",
    "   num_boost_round=2000,\n",
    "   evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "   verbose_eval=40,\n",
    "   early_stopping_rounds=100,\n",
    ")\n",
    "print(f\"best score {model.best_score:.5f} at iteration {model.best_iteration}\")\n",
    "model.save_model(f\"{job_dir}/model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6da2370-9acb-42fa-894f-c4da29da6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.9926\n",
      "y_pred=(933,)\n",
      "[0.99992895 0.9997522  0.99393684 0.9301336  0.99846566]\n",
      "CPU times: user 370 ms, sys: 462 ms, total: 831 ms\n",
      "Wall time: 64.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_true = val[label].tolist()\n",
    "y_pred = model.predict(data=dval, iteration_range=(0, model.best_iteration+1))\n",
    "auc = roc_auc_score(y_true, y_pred, average=\"macro\")\n",
    "print(f\"auc={auc:.4f}\")\n",
    "print(f\"y_pred={y_pred.shape}\\n{y_pred[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f793a39d-7bce-4472-aef3-bacde89ee929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models/xgb/20240121_021130/importance.csv\n",
      "CPU times: user 22.1 ms, sys: 46.6 ms, total: 68.7 ms\n",
      "Wall time: 6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>320</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>661.597534</td>\n",
       "      <td>580.991089</td>\n",
       "      <td>520.642212</td>\n",
       "      <td>405.889587</td>\n",
       "      <td>380.618866</td>\n",
       "      <td>240.466797</td>\n",
       "      <td>239.409851</td>\n",
       "      <td>238.442108</td>\n",
       "      <td>218.278152</td>\n",
       "      <td>187.281799</td>\n",
       "      <td>184.298508</td>\n",
       "      <td>181.102798</td>\n",
       "      <td>176.987335</td>\n",
       "      <td>132.721313</td>\n",
       "      <td>129.132324</td>\n",
       "      <td>104.596504</td>\n",
       "      <td>101.635033</td>\n",
       "      <td>100.086754</td>\n",
       "      <td>93.471291</td>\n",
       "      <td>92.816116</td>\n",
       "      <td>89.992638</td>\n",
       "      <td>85.454712</td>\n",
       "      <td>83.987701</td>\n",
       "      <td>83.834717</td>\n",
       "      <td>83.344002</td>\n",
       "      <td>82.944618</td>\n",
       "      <td>81.014114</td>\n",
       "      <td>79.86113</td>\n",
       "      <td>76.984772</td>\n",
       "      <td>74.992149</td>\n",
       "      <td>74.731422</td>\n",
       "      <td>73.908203</td>\n",
       "      <td>71.399536</td>\n",
       "      <td>71.09333</td>\n",
       "      <td>70.566414</td>\n",
       "      <td>70.2481</td>\n",
       "      <td>68.868896</td>\n",
       "      <td>67.324066</td>\n",
       "      <td>65.838104</td>\n",
       "      <td>64.030273</td>\n",
       "      <td>62.71357</td>\n",
       "      <td>61.870018</td>\n",
       "      <td>57.530853</td>\n",
       "      <td>51.854958</td>\n",
       "      <td>51.35556</td>\n",
       "      <td>48.884918</td>\n",
       "      <td>48.155899</td>\n",
       "      <td>47.38916</td>\n",
       "      <td>46.347572</td>\n",
       "      <td>46.327637</td>\n",
       "      <td>44.562149</td>\n",
       "      <td>43.605053</td>\n",
       "      <td>41.729317</td>\n",
       "      <td>41.457748</td>\n",
       "      <td>40.443329</td>\n",
       "      <td>40.406376</td>\n",
       "      <td>40.144859</td>\n",
       "      <td>40.034851</td>\n",
       "      <td>39.036804</td>\n",
       "      <td>37.398949</td>\n",
       "      <td>36.848492</td>\n",
       "      <td>36.416351</td>\n",
       "      <td>36.176056</td>\n",
       "      <td>35.987251</td>\n",
       "      <td>35.579456</td>\n",
       "      <td>35.425541</td>\n",
       "      <td>35.103855</td>\n",
       "      <td>35.080502</td>\n",
       "      <td>34.496826</td>\n",
       "      <td>34.133518</td>\n",
       "      <td>33.192463</td>\n",
       "      <td>33.009266</td>\n",
       "      <td>32.06942</td>\n",
       "      <td>31.338507</td>\n",
       "      <td>31.083378</td>\n",
       "      <td>30.853495</td>\n",
       "      <td>30.797331</td>\n",
       "      <td>30.461609</td>\n",
       "      <td>30.381845</td>\n",
       "      <td>30.220469</td>\n",
       "      <td>30.090424</td>\n",
       "      <td>29.481979</td>\n",
       "      <td>29.011768</td>\n",
       "      <td>28.63522</td>\n",
       "      <td>28.425415</td>\n",
       "      <td>28.025711</td>\n",
       "      <td>27.071001</td>\n",
       "      <td>26.896776</td>\n",
       "      <td>26.888142</td>\n",
       "      <td>25.628754</td>\n",
       "      <td>25.48353</td>\n",
       "      <td>25.275902</td>\n",
       "      <td>24.018242</td>\n",
       "      <td>23.696852</td>\n",
       "      <td>23.588829</td>\n",
       "      <td>23.426626</td>\n",
       "      <td>22.660467</td>\n",
       "      <td>22.441732</td>\n",
       "      <td>21.596815</td>\n",
       "      <td>21.554689</td>\n",
       "      <td>21.009773</td>\n",
       "      <td>20.925755</td>\n",
       "      <td>20.504051</td>\n",
       "      <td>20.193283</td>\n",
       "      <td>19.988934</td>\n",
       "      <td>19.944071</td>\n",
       "      <td>19.927662</td>\n",
       "      <td>19.911245</td>\n",
       "      <td>19.811428</td>\n",
       "      <td>19.766273</td>\n",
       "      <td>19.749308</td>\n",
       "      <td>18.282394</td>\n",
       "      <td>17.880573</td>\n",
       "      <td>17.86974</td>\n",
       "      <td>17.673416</td>\n",
       "      <td>17.618467</td>\n",
       "      <td>17.211958</td>\n",
       "      <td>17.182722</td>\n",
       "      <td>17.172173</td>\n",
       "      <td>17.163725</td>\n",
       "      <td>16.976942</td>\n",
       "      <td>16.936079</td>\n",
       "      <td>16.326605</td>\n",
       "      <td>16.122314</td>\n",
       "      <td>16.105356</td>\n",
       "      <td>15.895791</td>\n",
       "      <td>15.562007</td>\n",
       "      <td>15.558497</td>\n",
       "      <td>15.534515</td>\n",
       "      <td>15.273863</td>\n",
       "      <td>15.072861</td>\n",
       "      <td>14.98022</td>\n",
       "      <td>14.947492</td>\n",
       "      <td>14.851101</td>\n",
       "      <td>14.493192</td>\n",
       "      <td>14.252938</td>\n",
       "      <td>14.102311</td>\n",
       "      <td>13.970284</td>\n",
       "      <td>13.9264</td>\n",
       "      <td>13.918358</td>\n",
       "      <td>13.861259</td>\n",
       "      <td>13.493904</td>\n",
       "      <td>13.470053</td>\n",
       "      <td>13.438181</td>\n",
       "      <td>13.337593</td>\n",
       "      <td>13.245678</td>\n",
       "      <td>13.207893</td>\n",
       "      <td>13.118791</td>\n",
       "      <td>12.846616</td>\n",
       "      <td>12.750061</td>\n",
       "      <td>12.54248</td>\n",
       "      <td>12.52393</td>\n",
       "      <td>12.301524</td>\n",
       "      <td>11.99415</td>\n",
       "      <td>11.922365</td>\n",
       "      <td>11.901738</td>\n",
       "      <td>11.842185</td>\n",
       "      <td>11.512276</td>\n",
       "      <td>11.431728</td>\n",
       "      <td>11.384054</td>\n",
       "      <td>11.293309</td>\n",
       "      <td>11.093381</td>\n",
       "      <td>11.012393</td>\n",
       "      <td>10.879386</td>\n",
       "      <td>10.878849</td>\n",
       "      <td>10.830639</td>\n",
       "      <td>10.635188</td>\n",
       "      <td>10.585239</td>\n",
       "      <td>10.170173</td>\n",
       "      <td>10.123187</td>\n",
       "      <td>10.088881</td>\n",
       "      <td>9.934095</td>\n",
       "      <td>9.919516</td>\n",
       "      <td>9.795685</td>\n",
       "      <td>9.609342</td>\n",
       "      <td>9.30803</td>\n",
       "      <td>9.182851</td>\n",
       "      <td>9.158499</td>\n",
       "      <td>8.998846</td>\n",
       "      <td>8.933435</td>\n",
       "      <td>8.846701</td>\n",
       "      <td>8.821812</td>\n",
       "      <td>8.712491</td>\n",
       "      <td>8.708257</td>\n",
       "      <td>8.676237</td>\n",
       "      <td>8.652871</td>\n",
       "      <td>8.645793</td>\n",
       "      <td>8.37716</td>\n",
       "      <td>8.307696</td>\n",
       "      <td>8.267982</td>\n",
       "      <td>8.182672</td>\n",
       "      <td>8.168635</td>\n",
       "      <td>8.04805</td>\n",
       "      <td>8.044981</td>\n",
       "      <td>7.892286</td>\n",
       "      <td>7.854073</td>\n",
       "      <td>7.656933</td>\n",
       "      <td>7.611191</td>\n",
       "      <td>7.552275</td>\n",
       "      <td>7.481313</td>\n",
       "      <td>7.388374</td>\n",
       "      <td>7.209621</td>\n",
       "      <td>7.118626</td>\n",
       "      <td>7.115748</td>\n",
       "      <td>7.05514</td>\n",
       "      <td>6.978959</td>\n",
       "      <td>6.890601</td>\n",
       "      <td>6.886446</td>\n",
       "      <td>6.645034</td>\n",
       "      <td>6.530092</td>\n",
       "      <td>6.507767</td>\n",
       "      <td>6.349953</td>\n",
       "      <td>6.294907</td>\n",
       "      <td>6.280403</td>\n",
       "      <td>6.208178</td>\n",
       "      <td>6.202746</td>\n",
       "      <td>6.104156</td>\n",
       "      <td>5.964964</td>\n",
       "      <td>5.837977</td>\n",
       "      <td>5.818327</td>\n",
       "      <td>5.815298</td>\n",
       "      <td>5.709992</td>\n",
       "      <td>5.631436</td>\n",
       "      <td>5.620426</td>\n",
       "      <td>5.614038</td>\n",
       "      <td>5.596033</td>\n",
       "      <td>5.529945</td>\n",
       "      <td>5.419085</td>\n",
       "      <td>5.402081</td>\n",
       "      <td>5.380029</td>\n",
       "      <td>5.340683</td>\n",
       "      <td>5.328637</td>\n",
       "      <td>5.256274</td>\n",
       "      <td>5.252212</td>\n",
       "      <td>5.23568</td>\n",
       "      <td>5.208162</td>\n",
       "      <td>5.194965</td>\n",
       "      <td>5.065253</td>\n",
       "      <td>4.885905</td>\n",
       "      <td>4.847053</td>\n",
       "      <td>4.773505</td>\n",
       "      <td>4.769887</td>\n",
       "      <td>4.724706</td>\n",
       "      <td>4.714436</td>\n",
       "      <td>4.70049</td>\n",
       "      <td>4.694871</td>\n",
       "      <td>4.612142</td>\n",
       "      <td>4.607749</td>\n",
       "      <td>4.582759</td>\n",
       "      <td>4.522965</td>\n",
       "      <td>4.480743</td>\n",
       "      <td>4.444437</td>\n",
       "      <td>4.342023</td>\n",
       "      <td>4.305319</td>\n",
       "      <td>4.24401</td>\n",
       "      <td>4.198876</td>\n",
       "      <td>4.120795</td>\n",
       "      <td>4.090305</td>\n",
       "      <td>4.023343</td>\n",
       "      <td>3.994397</td>\n",
       "      <td>3.959758</td>\n",
       "      <td>3.944437</td>\n",
       "      <td>3.885608</td>\n",
       "      <td>3.847145</td>\n",
       "      <td>3.78024</td>\n",
       "      <td>3.763478</td>\n",
       "      <td>3.714287</td>\n",
       "      <td>3.700971</td>\n",
       "      <td>3.526972</td>\n",
       "      <td>3.512095</td>\n",
       "      <td>3.493603</td>\n",
       "      <td>3.466834</td>\n",
       "      <td>3.453146</td>\n",
       "      <td>3.450044</td>\n",
       "      <td>3.433106</td>\n",
       "      <td>3.419986</td>\n",
       "      <td>3.397957</td>\n",
       "      <td>3.395497</td>\n",
       "      <td>3.367174</td>\n",
       "      <td>3.367153</td>\n",
       "      <td>3.365255</td>\n",
       "      <td>3.361254</td>\n",
       "      <td>3.312541</td>\n",
       "      <td>3.234521</td>\n",
       "      <td>3.197531</td>\n",
       "      <td>3.197361</td>\n",
       "      <td>3.196799</td>\n",
       "      <td>3.183557</td>\n",
       "      <td>3.144096</td>\n",
       "      <td>3.066222</td>\n",
       "      <td>2.936248</td>\n",
       "      <td>2.93553</td>\n",
       "      <td>2.911227</td>\n",
       "      <td>2.909382</td>\n",
       "      <td>2.902889</td>\n",
       "      <td>2.888231</td>\n",
       "      <td>2.874432</td>\n",
       "      <td>2.86217</td>\n",
       "      <td>2.849054</td>\n",
       "      <td>2.814121</td>\n",
       "      <td>2.794135</td>\n",
       "      <td>2.793975</td>\n",
       "      <td>2.791943</td>\n",
       "      <td>2.78416</td>\n",
       "      <td>2.773086</td>\n",
       "      <td>2.738538</td>\n",
       "      <td>2.731679</td>\n",
       "      <td>2.711715</td>\n",
       "      <td>2.682313</td>\n",
       "      <td>2.680587</td>\n",
       "      <td>2.666754</td>\n",
       "      <td>2.652306</td>\n",
       "      <td>2.65118</td>\n",
       "      <td>2.642481</td>\n",
       "      <td>2.625511</td>\n",
       "      <td>2.625185</td>\n",
       "      <td>2.616417</td>\n",
       "      <td>2.590504</td>\n",
       "      <td>2.590005</td>\n",
       "      <td>2.567017</td>\n",
       "      <td>2.564539</td>\n",
       "      <td>2.542941</td>\n",
       "      <td>2.501905</td>\n",
       "      <td>2.483153</td>\n",
       "      <td>2.456413</td>\n",
       "      <td>2.449562</td>\n",
       "      <td>2.417475</td>\n",
       "      <td>2.385181</td>\n",
       "      <td>2.373887</td>\n",
       "      <td>2.36267</td>\n",
       "      <td>2.347529</td>\n",
       "      <td>2.33098</td>\n",
       "      <td>2.329677</td>\n",
       "      <td>2.327633</td>\n",
       "      <td>2.265077</td>\n",
       "      <td>2.251067</td>\n",
       "      <td>2.200758</td>\n",
       "      <td>2.193883</td>\n",
       "      <td>2.19388</td>\n",
       "      <td>2.189415</td>\n",
       "      <td>2.165207</td>\n",
       "      <td>2.122313</td>\n",
       "      <td>2.11352</td>\n",
       "      <td>2.111507</td>\n",
       "      <td>2.108935</td>\n",
       "      <td>2.073899</td>\n",
       "      <td>2.062941</td>\n",
       "      <td>2.042671</td>\n",
       "      <td>2.038351</td>\n",
       "      <td>2.037022</td>\n",
       "      <td>2.026715</td>\n",
       "      <td>2.002</td>\n",
       "      <td>1.994819</td>\n",
       "      <td>1.905548</td>\n",
       "      <td>1.902783</td>\n",
       "      <td>1.895117</td>\n",
       "      <td>1.878437</td>\n",
       "      <td>1.869759</td>\n",
       "      <td>1.838896</td>\n",
       "      <td>1.81638</td>\n",
       "      <td>1.790969</td>\n",
       "      <td>1.787349</td>\n",
       "      <td>1.784771</td>\n",
       "      <td>1.781002</td>\n",
       "      <td>1.776031</td>\n",
       "      <td>1.745369</td>\n",
       "      <td>1.716723</td>\n",
       "      <td>1.716033</td>\n",
       "      <td>1.697812</td>\n",
       "      <td>1.693832</td>\n",
       "      <td>1.69218</td>\n",
       "      <td>1.690742</td>\n",
       "      <td>1.672335</td>\n",
       "      <td>1.666259</td>\n",
       "      <td>1.65098</td>\n",
       "      <td>1.637237</td>\n",
       "      <td>1.627404</td>\n",
       "      <td>1.561339</td>\n",
       "      <td>1.559408</td>\n",
       "      <td>1.554674</td>\n",
       "      <td>1.518231</td>\n",
       "      <td>1.497944</td>\n",
       "      <td>1.483841</td>\n",
       "      <td>1.480845</td>\n",
       "      <td>1.459464</td>\n",
       "      <td>1.442078</td>\n",
       "      <td>1.425265</td>\n",
       "      <td>1.293403</td>\n",
       "      <td>1.277447</td>\n",
       "      <td>1.265386</td>\n",
       "      <td>1.251879</td>\n",
       "      <td>1.138635</td>\n",
       "      <td>1.136488</td>\n",
       "      <td>1.079514</td>\n",
       "      <td>1.023715</td>\n",
       "      <td>1.015635</td>\n",
       "      <td>1.003615</td>\n",
       "      <td>0.979889</td>\n",
       "      <td>0.976981</td>\n",
       "      <td>0.897438</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.864037</td>\n",
       "      <td>0.756007</td>\n",
       "      <td>0.705514</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>0.633369</td>\n",
       "      <td>0.545553</td>\n",
       "      <td>0.545249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>ts_polysyllable_frac</td>\n",
       "      <td>tf_Ġhey</td>\n",
       "      <td>ts_syllables_per_word</td>\n",
       "      <td>ch_space_frac</td>\n",
       "      <td>tf_Ġsuper</td>\n",
       "      <td>tf_Ġdr</td>\n",
       "      <td>tf_Ġgoals</td>\n",
       "      <td>tf_Ġbecause</td>\n",
       "      <td>tf_Ġhuang</td>\n",
       "      <td>tf_Ġachieve</td>\n",
       "      <td>tf_Ġadditionally</td>\n",
       "      <td>tf_Ġessay</td>\n",
       "      <td>ts_smog_index</td>\n",
       "      <td>tf_Ġcultures</td>\n",
       "      <td>tf_Ġnt</td>\n",
       "      <td>tf_Ġconclusion</td>\n",
       "      <td>tf_Ġgrader</td>\n",
       "      <td>tf_Ġsustainable</td>\n",
       "      <td>tf_Ġessential</td>\n",
       "      <td>tf_th</td>\n",
       "      <td>tf_Ġvery</td>\n",
       "      <td>tf_Ġemerson</td>\n",
       "      <td>tf_Ġseas</td>\n",
       "      <td>tf_Ġwould</td>\n",
       "      <td>tf_Ġdear</td>\n",
       "      <td>tf_Ġimportant</td>\n",
       "      <td>ws_sent_len_std</td>\n",
       "      <td>ts_monosyllable_frac</td>\n",
       "      <td>tf_Ġelectors</td>\n",
       "      <td>tf_Ġsuccess</td>\n",
       "      <td>tf_Ġquality</td>\n",
       "      <td>tf_Ġattempt</td>\n",
       "      <td>tf_Ġcowboy</td>\n",
       "      <td>ch_punc_frac</td>\n",
       "      <td>ts_lexicon_count</td>\n",
       "      <td>tf_Ġadventure</td>\n",
       "      <td>tf_Ġtotally</td>\n",
       "      <td>ch_digit_frac</td>\n",
       "      <td>tf_Ġfirstly</td>\n",
       "      <td>tf_Ġconfused</td>\n",
       "      <td>tf_Ġexperiences</td>\n",
       "      <td>tf_Ġensures</td>\n",
       "      <td>tf_Ġemotion</td>\n",
       "      <td>tf_Ġskills</td>\n",
       "      <td>tf_Ġimportance</td>\n",
       "      <td>tf_Ġand</td>\n",
       "      <td>tf_Ġbeyond</td>\n",
       "      <td>tf_Ġelection</td>\n",
       "      <td>tf_Ġultimately</td>\n",
       "      <td>tf_Ġpursue</td>\n",
       "      <td>tf_Ġthen</td>\n",
       "      <td>tf_Ġaddress</td>\n",
       "      <td>tf_Ġsenator</td>\n",
       "      <td>tf_Ġcomputer</td>\n",
       "      <td>tf_Ġpercent</td>\n",
       "      <td>tf_Ġwriting</td>\n",
       "      <td>tf_Ġchina</td>\n",
       "      <td>tf_Ġconcerns</td>\n",
       "      <td>tf_Ġachieving</td>\n",
       "      <td>tf_Ġoverall</td>\n",
       "      <td>tf_Ġpotential</td>\n",
       "      <td>ch_letter_frac</td>\n",
       "      <td>tf_Ġstuff</td>\n",
       "      <td>tf_Ġcar</td>\n",
       "      <td>tf_Ġeurope</td>\n",
       "      <td>tf_Ġlike</td>\n",
       "      <td>tf_Ġchallenges</td>\n",
       "      <td>tf_Ġ10</td>\n",
       "      <td>tf_Ġperspectives</td>\n",
       "      <td>ts_syllable_count</td>\n",
       "      <td>tf_Ġparagraph</td>\n",
       "      <td>tf_Ġvenus</td>\n",
       "      <td>ts_coleman_liau_index</td>\n",
       "      <td>tf_Ġalthough</td>\n",
       "      <td>tf_Ġsignificant</td>\n",
       "      <td>tf_Ġprobably</td>\n",
       "      <td>tf_Ġsmaller</td>\n",
       "      <td>tf_Ġhumans</td>\n",
       "      <td>tf_Ġlead</td>\n",
       "      <td>ts_difficult_words</td>\n",
       "      <td>tf_Ġplus</td>\n",
       "      <td>ch_len</td>\n",
       "      <td>ws_sent_len_delta_mean</td>\n",
       "      <td>ws_sent_len_delta_std</td>\n",
       "      <td>tf_Ġourselves</td>\n",
       "      <td>tf_Ġsecondly</td>\n",
       "      <td>tf_Ġetc</td>\n",
       "      <td>tf_Ġfacial</td>\n",
       "      <td>tf_Ġnasa</td>\n",
       "      <td>tf_Ġanimals</td>\n",
       "      <td>tf_Ġextracurricular</td>\n",
       "      <td>tf_Ġthe</td>\n",
       "      <td>tf_Ġprovide</td>\n",
       "      <td>ts_sentence_count</td>\n",
       "      <td>tf_Ġpossibly</td>\n",
       "      <td>tf_Ġleast</td>\n",
       "      <td>tf_Ġ8</td>\n",
       "      <td>tf_Ġseagoing</td>\n",
       "      <td>tf_Ġcool</td>\n",
       "      <td>tf_Ġmy</td>\n",
       "      <td>tf_Ġschool</td>\n",
       "      <td>tf_Ġapproach</td>\n",
       "      <td>tf_Ġhuman</td>\n",
       "      <td>tf_Ġinformed</td>\n",
       "      <td>tf_Ġensure</td>\n",
       "      <td>tf_Ġargue</td>\n",
       "      <td>tf_Ġcommunity</td>\n",
       "      <td>tf_Ġstates</td>\n",
       "      <td>tf_Ġus</td>\n",
       "      <td>tf_Ġactivity</td>\n",
       "      <td>tf_Ġme</td>\n",
       "      <td>tf_Ġunited</td>\n",
       "      <td>tf_Ġtext</td>\n",
       "      <td>tf_Ġprincipal</td>\n",
       "      <td>tf_Ġbalance</td>\n",
       "      <td>tf_Ġpresident</td>\n",
       "      <td>tf_Ġeveryday</td>\n",
       "      <td>tf_Ġresources</td>\n",
       "      <td>tf_Ġunique</td>\n",
       "      <td>tf_Ġdriving</td>\n",
       "      <td>tf_Ġconsider</td>\n",
       "      <td>tf_Ġtrue</td>\n",
       "      <td>tf_Ġcars</td>\n",
       "      <td>ts_spache_readability</td>\n",
       "      <td>tf_Ġmany</td>\n",
       "      <td>tf_Ġservice</td>\n",
       "      <td>tf_Ġyou</td>\n",
       "      <td>tf_Ġdo</td>\n",
       "      <td>tf_Ġbeneficial</td>\n",
       "      <td>tf_Ġgrade</td>\n",
       "      <td>tf_Ġreduce</td>\n",
       "      <td>tf_Ġshould</td>\n",
       "      <td>tf_Ġstudent</td>\n",
       "      <td>tf_Ġearth</td>\n",
       "      <td>ts_gunning_fog</td>\n",
       "      <td>tf_Ġallows</td>\n",
       "      <td>tf_Ġstudents</td>\n",
       "      <td>ws_sent_len_mean</td>\n",
       "      <td>va_valence_mean</td>\n",
       "      <td>tf_Ġmean</td>\n",
       "      <td>ts_flesch_reading_ease</td>\n",
       "      <td>tf_Ġreducing</td>\n",
       "      <td>tf_Ġdifficult</td>\n",
       "      <td>tf_Ġdesigned</td>\n",
       "      <td>tf_Ġcomputers</td>\n",
       "      <td>tf_Ġalmost</td>\n",
       "      <td>tf_Ġadvice</td>\n",
       "      <td>tf_Ġif</td>\n",
       "      <td>tf_Ġpublic</td>\n",
       "      <td>tf_Ġday</td>\n",
       "      <td>tf_Ġsmog</td>\n",
       "      <td>tf_Ġhand</td>\n",
       "      <td>ts_dale_chall_readability_score</td>\n",
       "      <td>tf_Ġfair</td>\n",
       "      <td>tf_Ġwe</td>\n",
       "      <td>ts_syllables_per_sent</td>\n",
       "      <td>tf_Ġsupport</td>\n",
       "      <td>tf_Ġsport</td>\n",
       "      <td>tf_Ġtechnology</td>\n",
       "      <td>tf_Ġhealth</td>\n",
       "      <td>tf_Ġgo</td>\n",
       "      <td>tf_Ġdrive</td>\n",
       "      <td>tf_Ġremember</td>\n",
       "      <td>va_arousal_mean</td>\n",
       "      <td>tf_Ġfurthermore</td>\n",
       "      <td>tf_Ġparticipate</td>\n",
       "      <td>tf_Ġopportunities</td>\n",
       "      <td>ch_upper_frac</td>\n",
       "      <td>tf_Ġwhile</td>\n",
       "      <td>tf_Ġget</td>\n",
       "      <td>tf_Ġimpact</td>\n",
       "      <td>tf_Ġfocus</td>\n",
       "      <td>tf_Ġcreate</td>\n",
       "      <td>tf_Ġso</td>\n",
       "      <td>tf_Ġpoint</td>\n",
       "      <td>tf_Ġrisks</td>\n",
       "      <td>tf_Ġlet</td>\n",
       "      <td>tf_Ġi</td>\n",
       "      <td>tf_Ġthough</td>\n",
       "      <td>tf_Ġhowever</td>\n",
       "      <td>tf_Ġwill</td>\n",
       "      <td>tf_Ġmost</td>\n",
       "      <td>tf_Ġmight</td>\n",
       "      <td>ts_mcalpine_eflaw</td>\n",
       "      <td>tf_Ġstate</td>\n",
       "      <td>tf_Ġfinally</td>\n",
       "      <td>tf_Ġexperience</td>\n",
       "      <td>tf_Ġsincerely</td>\n",
       "      <td>tf_Ġwas</td>\n",
       "      <td>tf_Ġcould</td>\n",
       "      <td>va_dominance_mean</td>\n",
       "      <td>tf_Ġlearn</td>\n",
       "      <td>tf_Ġam</td>\n",
       "      <td>tf_Ġlearning</td>\n",
       "      <td>tf_Ġinterests</td>\n",
       "      <td>tf_Ġit</td>\n",
       "      <td>tf_Ġboth</td>\n",
       "      <td>tf_Ġshow</td>\n",
       "      <td>tf_Ġmuch</td>\n",
       "      <td>tf_Ġkids</td>\n",
       "      <td>tf_Ġcell</td>\n",
       "      <td>tf_Ġstudying</td>\n",
       "      <td>tf_Ġlearned</td>\n",
       "      <td>tf_Ġpeople</td>\n",
       "      <td>tf_Ġthey</td>\n",
       "      <td>tf_Ġoptions</td>\n",
       "      <td>tf_Ġunderstand</td>\n",
       "      <td>tf_Ġexplore</td>\n",
       "      <td>tf_Ġoften</td>\n",
       "      <td>tf_Ġroad</td>\n",
       "      <td>tf_Ġclear</td>\n",
       "      <td>tf_Ġexpress</td>\n",
       "      <td>tf_Ġmistakes</td>\n",
       "      <td>tf_Ġmeans</td>\n",
       "      <td>tf_Ġthank</td>\n",
       "      <td>tf_Ġwho</td>\n",
       "      <td>tf_Ġadvantages</td>\n",
       "      <td>tf_Ġmatter</td>\n",
       "      <td>tf_Ġwhat</td>\n",
       "      <td>tf_Ġplanet</td>\n",
       "      <td>tf_Ġyour</td>\n",
       "      <td>tf_Ġmay</td>\n",
       "      <td>tf_Ġfeel</td>\n",
       "      <td>tf_Ġrequired</td>\n",
       "      <td>tf_Ġits</td>\n",
       "      <td>tf_Ġown</td>\n",
       "      <td>tf_Ġbenefits</td>\n",
       "      <td>tf_Ġbelieve</td>\n",
       "      <td>tf_Ġprojects</td>\n",
       "      <td>tf_Ġteacher</td>\n",
       "      <td>tf_Ġ3</td>\n",
       "      <td>tf_Ġis</td>\n",
       "      <td>tf_Ġhard</td>\n",
       "      <td>ts_words_per_sent</td>\n",
       "      <td>tf_Ġschools</td>\n",
       "      <td>tf_Ġbut</td>\n",
       "      <td>tf_Ġnot</td>\n",
       "      <td>tf_Ġagree</td>\n",
       "      <td>tf_Ġall</td>\n",
       "      <td>tf_Ġat</td>\n",
       "      <td>tf_Ġwhether</td>\n",
       "      <td>tf_Ġcan</td>\n",
       "      <td>tf_Ġmake</td>\n",
       "      <td>tf_Ġno</td>\n",
       "      <td>tf_Ġspend</td>\n",
       "      <td>tf_Ġwhy</td>\n",
       "      <td>tf_Ġfirst</td>\n",
       "      <td>tf_Ġexample</td>\n",
       "      <td>tf_Ġgoing</td>\n",
       "      <td>tf_Ġname</td>\n",
       "      <td>tf_Ġable</td>\n",
       "      <td>tf_Ġabout</td>\n",
       "      <td>tf_Ġto</td>\n",
       "      <td>tf_Ġhelping</td>\n",
       "      <td>tf_Ġgiven</td>\n",
       "      <td>tf_Ġfor</td>\n",
       "      <td>tf_Ġactivities</td>\n",
       "      <td>tf_Ġsports</td>\n",
       "      <td>tf_Ġanother</td>\n",
       "      <td>tf_Ġlives</td>\n",
       "      <td>tf_Ġeverything</td>\n",
       "      <td>tf_Ġimagine</td>\n",
       "      <td>ts_flesch_kincaid_grade</td>\n",
       "      <td>tf_Ġsummer</td>\n",
       "      <td>tf_Ġthink</td>\n",
       "      <td>tf_Ġsay</td>\n",
       "      <td>ts_linsear_write_formula</td>\n",
       "      <td>tf_Ġour</td>\n",
       "      <td>tf_Ġbenefit</td>\n",
       "      <td>va_valence_std</td>\n",
       "      <td>tf_Ġstart</td>\n",
       "      <td>tf_Ġfact</td>\n",
       "      <td>va_dominance_std</td>\n",
       "      <td>tf_Ġan</td>\n",
       "      <td>tf_Ġbad</td>\n",
       "      <td>tf_Ġask</td>\n",
       "      <td>va_arousal_std</td>\n",
       "      <td>tf_Ġkeep</td>\n",
       "      <td>tf_Ġparents</td>\n",
       "      <td>tf_Ġgood</td>\n",
       "      <td>tf_Ġlast</td>\n",
       "      <td>tf_Ġstudies</td>\n",
       "      <td>tf_Ġtheir</td>\n",
       "      <td>tf_Ġworth</td>\n",
       "      <td>tf_Ġafter</td>\n",
       "      <td>tf_Ġgives</td>\n",
       "      <td>tf_Ġreason</td>\n",
       "      <td>tf_Ġnow</td>\n",
       "      <td>tf_Ġthese</td>\n",
       "      <td>tf_Ġtherefore</td>\n",
       "      <td>tf_Ġinstead</td>\n",
       "      <td>tf_Ġone</td>\n",
       "      <td>tf_Ġaround</td>\n",
       "      <td>tf_Ġare</td>\n",
       "      <td>tf_Ġtoo</td>\n",
       "      <td>tf_Ġhow</td>\n",
       "      <td>tf_Ġaverage</td>\n",
       "      <td>tf_Ġknow</td>\n",
       "      <td>tf_Ġplace</td>\n",
       "      <td>tf_Ġfun</td>\n",
       "      <td>tf_Ġphone</td>\n",
       "      <td>tf_Ġwere</td>\n",
       "      <td>tf_Ġcause</td>\n",
       "      <td>tf_Ġlife</td>\n",
       "      <td>tf_Ġbeing</td>\n",
       "      <td>tf_Ġhome</td>\n",
       "      <td>tf_Ġa</td>\n",
       "      <td>tf_Ġthan</td>\n",
       "      <td>tf_Ġbe</td>\n",
       "      <td>tf_Ġrather</td>\n",
       "      <td>tf_Ġworld</td>\n",
       "      <td>tf_Ġhaving</td>\n",
       "      <td>ts_automated_readability_index</td>\n",
       "      <td>tf_Ġin</td>\n",
       "      <td>tf_Ġsense</td>\n",
       "      <td>tf_Ġdown</td>\n",
       "      <td>tf_Ġthis</td>\n",
       "      <td>ch_repeat_char_frac</td>\n",
       "      <td>tf_Ġthat</td>\n",
       "      <td>tf_Ġsince</td>\n",
       "      <td>tf_Ġothers</td>\n",
       "      <td>tf_Ġhis</td>\n",
       "      <td>tf_Ġstay</td>\n",
       "      <td>tf_Ġwith</td>\n",
       "      <td>tf_Ġout</td>\n",
       "      <td>tf_Ġbecome</td>\n",
       "      <td>tf_Ġdoing</td>\n",
       "      <td>tf_Ġallow</td>\n",
       "      <td>tf_Ġreally</td>\n",
       "      <td>tf_Ġwhen</td>\n",
       "      <td>tf_Ġtry</td>\n",
       "      <td>tf_Ġhigh</td>\n",
       "      <td>tf_Ġoff</td>\n",
       "      <td>tf_Ġteach</td>\n",
       "      <td>tf_Ġs</td>\n",
       "      <td>tf_Ġjust</td>\n",
       "      <td>tf_Ġthing</td>\n",
       "      <td>tf_Ġtime</td>\n",
       "      <td>tf_Ġway</td>\n",
       "      <td>tf_Ġstill</td>\n",
       "      <td>tf_Ġattention</td>\n",
       "      <td>tf_Ġwhich</td>\n",
       "      <td>tf_Ġtake</td>\n",
       "      <td>tf_Ġput</td>\n",
       "      <td>tf_Ġup</td>\n",
       "      <td>tf_Ġany</td>\n",
       "      <td>tf_Ġthere</td>\n",
       "      <td>tf_Ġwithout</td>\n",
       "      <td>tf_Ġother</td>\n",
       "      <td>tf_Ġhave</td>\n",
       "      <td>tf_Ġmore</td>\n",
       "      <td>tf_Ġof</td>\n",
       "      <td>tf_Ġeven</td>\n",
       "      <td>tf_Ġor</td>\n",
       "      <td>tf_Ġbeen</td>\n",
       "      <td>tf_Ġtaking</td>\n",
       "      <td>tf_Ġsee</td>\n",
       "      <td>tf_Ġimprove</td>\n",
       "      <td>tf_Ġbetter</td>\n",
       "      <td>tf_Ġdone</td>\n",
       "      <td>tf_Ġsame</td>\n",
       "      <td>tf_Ġon</td>\n",
       "      <td>tf_Ġthem</td>\n",
       "      <td>tf_Ġuse</td>\n",
       "      <td>tf_Ġtimes</td>\n",
       "      <td>tf_Ġsuch</td>\n",
       "      <td>tf_Ġfrom</td>\n",
       "      <td>tf_Ġdifferent</td>\n",
       "      <td>tf_Ġas</td>\n",
       "      <td>tf_Ġwant</td>\n",
       "      <td>tf_Ġgive</td>\n",
       "      <td>tf_Ġidea</td>\n",
       "      <td>tf_Ġhelp</td>\n",
       "      <td>tf_Ġusing</td>\n",
       "      <td>tf_Ġnew</td>\n",
       "      <td>tf_Ġmakes</td>\n",
       "      <td>tf_Ġonly</td>\n",
       "      <td>tf_Ġperson</td>\n",
       "      <td>tf_Ġevery</td>\n",
       "      <td>tf_Ġmade</td>\n",
       "      <td>tf_Ġalso</td>\n",
       "      <td>tf_Ġthings</td>\n",
       "      <td>tf_Ġeach</td>\n",
       "      <td>tf_Ġsome</td>\n",
       "      <td>tf_Ġjob</td>\n",
       "      <td>tf_Ġless</td>\n",
       "      <td>tf_Ġlot</td>\n",
       "      <td>tf_Ġsaid</td>\n",
       "      <td>tf_Ġfriends</td>\n",
       "      <td>tf_Ġactually</td>\n",
       "      <td>tf_Ġduring</td>\n",
       "      <td>tf_Ġgreat</td>\n",
       "      <td>tf_Ġclass</td>\n",
       "      <td>tf_Ġmaybe</td>\n",
       "      <td>tf_Ġthose</td>\n",
       "      <td>tf_Ġnever</td>\n",
       "      <td>tf_Ġwhere</td>\n",
       "      <td>tf_Ġsomeone</td>\n",
       "      <td>tf_Ġsomething</td>\n",
       "      <td>tf_Ġby</td>\n",
       "      <td>tf_Ġaway</td>\n",
       "      <td>tf_Ġmaking</td>\n",
       "      <td>tf_Ġinto</td>\n",
       "      <td>tf_Ġthrough</td>\n",
       "      <td>tf_Ġtell</td>\n",
       "      <td>tf_Ġgas</td>\n",
       "      <td>tf_Ġlikely</td>\n",
       "      <td>tf_Ġfuture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1                      2    \\\n",
       "importance            661.597534  580.991089             520.642212   \n",
       "feature     ts_polysyllable_frac     tf_Ġhey  ts_syllables_per_word   \n",
       "\n",
       "                      3           4           5           6            7    \\\n",
       "importance     405.889587  380.618866  240.466797  239.409851   238.442108   \n",
       "feature     ch_space_frac   tf_Ġsuper      tf_Ġdr   tf_Ġgoals  tf_Ġbecause   \n",
       "\n",
       "                   8            9                 10          11   \\\n",
       "importance  218.278152   187.281799        184.298508  181.102798   \n",
       "feature      tf_Ġhuang  tf_Ġachieve  tf_Ġadditionally   tf_Ġessay   \n",
       "\n",
       "                      12            13          14              15   \\\n",
       "importance     176.987335    132.721313  129.132324      104.596504   \n",
       "feature     ts_smog_index  tf_Ġcultures      tf_Ġnt  tf_Ġconclusion   \n",
       "\n",
       "                   16               17             18         19         20   \\\n",
       "importance  101.635033       100.086754      93.471291  92.816116  89.992638   \n",
       "feature     tf_Ġgrader  tf_Ġsustainable  tf_Ġessential      tf_th   tf_Ġvery   \n",
       "\n",
       "                    21         22         23         24             25   \\\n",
       "importance    85.454712  83.987701  83.834717  83.344002      82.944618   \n",
       "feature     tf_Ġemerson   tf_Ġseas  tf_Ġwould   tf_Ġdear  tf_Ġimportant   \n",
       "\n",
       "                        26                    27            28           29   \\\n",
       "importance        81.014114              79.86113     76.984772    74.992149   \n",
       "feature     ws_sent_len_std  ts_monosyllable_frac  tf_Ġelectors  tf_Ġsuccess   \n",
       "\n",
       "                    30           31          32            33   \\\n",
       "importance    74.731422    73.908203   71.399536      71.09333   \n",
       "feature     tf_Ġquality  tf_Ġattempt  tf_Ġcowboy  ch_punc_frac   \n",
       "\n",
       "                         34             35           36             37   \\\n",
       "importance         70.566414        70.2481    68.868896      67.324066   \n",
       "feature     ts_lexicon_count  tf_Ġadventure  tf_Ġtotally  ch_digit_frac   \n",
       "\n",
       "                    38            39               40           41   \\\n",
       "importance    65.838104     64.030273         62.71357    61.870018   \n",
       "feature     tf_Ġfirstly  tf_Ġconfused  tf_Ġexperiences  tf_Ġensures   \n",
       "\n",
       "                    42          43              44         45          46   \\\n",
       "importance    57.530853   51.854958        51.35556  48.884918   48.155899   \n",
       "feature     tf_Ġemotion  tf_Ġskills  tf_Ġimportance    tf_Ġand  tf_Ġbeyond   \n",
       "\n",
       "                     47              48          49         50           51   \\\n",
       "importance      47.38916       46.347572   46.327637  44.562149    43.605053   \n",
       "feature     tf_Ġelection  tf_Ġultimately  tf_Ġpursue   tf_Ġthen  tf_Ġaddress   \n",
       "\n",
       "                    52            53           54           55         56   \\\n",
       "importance    41.729317     41.457748    40.443329    40.406376  40.144859   \n",
       "feature     tf_Ġsenator  tf_Ġcomputer  tf_Ġpercent  tf_Ġwriting  tf_Ġchina   \n",
       "\n",
       "                     57             58           59             60   \\\n",
       "importance     40.034851      39.036804    37.398949      36.848492   \n",
       "feature     tf_Ġconcerns  tf_Ġachieving  tf_Ġoverall  tf_Ġpotential   \n",
       "\n",
       "                       61         62         63          64         65   \\\n",
       "importance       36.416351  36.176056  35.987251   35.579456  35.425541   \n",
       "feature     ch_letter_frac  tf_Ġstuff    tf_Ġcar  tf_Ġeurope   tf_Ġlike   \n",
       "\n",
       "                       66         67                68                 69   \\\n",
       "importance       35.103855  35.080502         34.496826          34.133518   \n",
       "feature     tf_Ġchallenges     tf_Ġ10  tf_Ġperspectives  ts_syllable_count   \n",
       "\n",
       "                      70         71                     72            73   \\\n",
       "importance      33.192463  33.009266               32.06942     31.338507   \n",
       "feature     tf_Ġparagraph  tf_Ġvenus  ts_coleman_liau_index  tf_Ġalthough   \n",
       "\n",
       "                        74            75           76          77         78   \\\n",
       "importance        31.083378     30.853495    30.797331   30.461609  30.381845   \n",
       "feature     tf_Ġsignificant  tf_Ġprobably  tf_Ġsmaller  tf_Ġhumans   tf_Ġlead   \n",
       "\n",
       "                           79         80         81                      82   \\\n",
       "importance           30.220469  30.090424  29.481979               29.011768   \n",
       "feature     ts_difficult_words   tf_Ġplus     ch_len  ws_sent_len_delta_mean   \n",
       "\n",
       "                              83             84            85         86   \\\n",
       "importance               28.63522      28.425415     28.025711  27.071001   \n",
       "feature     ws_sent_len_delta_std  tf_Ġourselves  tf_Ġsecondly    tf_Ġetc   \n",
       "\n",
       "                   87         88           89                   90   \\\n",
       "importance   26.896776  26.888142    25.628754             25.48353   \n",
       "feature     tf_Ġfacial   tf_Ġnasa  tf_Ġanimals  tf_Ġextracurricular   \n",
       "\n",
       "                  91           92                 93            94   \\\n",
       "importance  25.275902    24.018242          23.696852     23.588829   \n",
       "feature       tf_Ġthe  tf_Ġprovide  ts_sentence_count  tf_Ġpossibly   \n",
       "\n",
       "                  95         96            97         98         99   \\\n",
       "importance  23.426626  22.660467     22.441732  21.596815  21.554689   \n",
       "feature     tf_Ġleast      tf_Ġ8  tf_Ġseagoing   tf_Ġcool     tf_Ġmy   \n",
       "\n",
       "                   100           101        102           103         104  \\\n",
       "importance   21.009773     20.925755  20.504051     20.193283   19.988934   \n",
       "feature     tf_Ġschool  tf_Ġapproach  tf_Ġhuman  tf_Ġinformed  tf_Ġensure   \n",
       "\n",
       "                  105            106         107        108           109  \\\n",
       "importance  19.944071      19.927662   19.911245  19.811428     19.766273   \n",
       "feature     tf_Ġargue  tf_Ġcommunity  tf_Ġstates     tf_Ġus  tf_Ġactivity   \n",
       "\n",
       "                  110         111        112            113          114  \\\n",
       "importance  19.749308   18.282394  17.880573       17.86974    17.673416   \n",
       "feature        tf_Ġme  tf_Ġunited   tf_Ġtext  tf_Ġprincipal  tf_Ġbalance   \n",
       "\n",
       "                      115           116            117         118  \\\n",
       "importance      17.618467     17.211958      17.182722   17.172173   \n",
       "feature     tf_Ġpresident  tf_Ġeveryday  tf_Ġresources  tf_Ġunique   \n",
       "\n",
       "                    119           120        121        122  \\\n",
       "importance    17.163725     16.976942  16.936079  16.326605   \n",
       "feature     tf_Ġdriving  tf_Ġconsider   tf_Ġtrue   tf_Ġcars   \n",
       "\n",
       "                              123        124          125        126  \\\n",
       "importance              16.122314  16.105356    15.895791  15.562007   \n",
       "feature     ts_spache_readability   tf_Ġmany  tf_Ġservice    tf_Ġyou   \n",
       "\n",
       "                  127             128        129         130         131  \\\n",
       "importance  15.558497       15.534515  15.273863   15.072861    14.98022   \n",
       "feature        tf_Ġdo  tf_Ġbeneficial  tf_Ġgrade  tf_Ġreduce  tf_Ġshould   \n",
       "\n",
       "                    132        133             134         135           136  \\\n",
       "importance    14.947492  14.851101       14.493192   14.252938     14.102311   \n",
       "feature     tf_Ġstudent  tf_Ġearth  ts_gunning_fog  tf_Ġallows  tf_Ġstudents   \n",
       "\n",
       "                         137              138        139  \\\n",
       "importance         13.970284          13.9264  13.918358   \n",
       "feature     ws_sent_len_mean  va_valence_mean   tf_Ġmean   \n",
       "\n",
       "                               140           141            142           143  \\\n",
       "importance               13.861259     13.493904      13.470053     13.438181   \n",
       "feature     ts_flesch_reading_ease  tf_Ġreducing  tf_Ġdifficult  tf_Ġdesigned   \n",
       "\n",
       "                      144         145         146        147         148  \\\n",
       "importance      13.337593   13.245678   13.207893  13.118791   12.846616   \n",
       "feature     tf_Ġcomputers  tf_Ġalmost  tf_Ġadvice     tf_Ġif  tf_Ġpublic   \n",
       "\n",
       "                  149       150       151                              152  \\\n",
       "importance  12.750061  12.54248  12.52393                        12.301524   \n",
       "feature       tf_Ġday  tf_Ġsmog  tf_Ġhand  ts_dale_chall_readability_score   \n",
       "\n",
       "                 153        154                    155          156  \\\n",
       "importance  11.99415  11.922365              11.901738    11.842185   \n",
       "feature     tf_Ġfair     tf_Ġwe  ts_syllables_per_sent  tf_Ġsupport   \n",
       "\n",
       "                  157             158         159        160        161  \\\n",
       "importance  11.512276       11.431728   11.384054  11.293309  11.093381   \n",
       "feature     tf_Ġsport  tf_Ġtechnology  tf_Ġhealth     tf_Ġgo  tf_Ġdrive   \n",
       "\n",
       "                     162              163              164              165  \\\n",
       "importance     11.012393        10.879386        10.878849        10.830639   \n",
       "feature     tf_Ġremember  va_arousal_mean  tf_Ġfurthermore  tf_Ġparticipate   \n",
       "\n",
       "                          166            167        168        169  \\\n",
       "importance          10.635188      10.585239  10.170173  10.123187   \n",
       "feature     tf_Ġopportunities  ch_upper_frac  tf_Ġwhile    tf_Ġget   \n",
       "\n",
       "                   170        171         172       173        174        175  \\\n",
       "importance   10.088881   9.934095    9.919516  9.795685   9.609342    9.30803   \n",
       "feature     tf_Ġimpact  tf_Ġfocus  tf_Ġcreate    tf_Ġso  tf_Ġpoint  tf_Ġrisks   \n",
       "\n",
       "                 176       177         178          179       180       181  \\\n",
       "importance  9.182851  9.158499    8.998846     8.933435  8.846701  8.821812   \n",
       "feature      tf_Ġlet     tf_Ġi  tf_Ġthough  tf_Ġhowever  tf_Ġwill  tf_Ġmost   \n",
       "\n",
       "                  182                183        184          185  \\\n",
       "importance   8.712491           8.708257   8.676237     8.652871   \n",
       "feature     tf_Ġmight  ts_mcalpine_eflaw  tf_Ġstate  tf_Ġfinally   \n",
       "\n",
       "                       186            187       188        189  \\\n",
       "importance        8.645793        8.37716  8.307696   8.267982   \n",
       "feature     tf_Ġexperience  tf_Ġsincerely   tf_Ġwas  tf_Ġcould   \n",
       "\n",
       "                          190        191      192           193  \\\n",
       "importance           8.182672   8.168635  8.04805      8.044981   \n",
       "feature     va_dominance_mean  tf_Ġlearn   tf_Ġam  tf_Ġlearning   \n",
       "\n",
       "                      194       195       196       197       198       199  \\\n",
       "importance       7.892286  7.854073  7.656933  7.611191  7.552275  7.481313   \n",
       "feature     tf_Ġinterests    tf_Ġit  tf_Ġboth  tf_Ġshow  tf_Ġmuch  tf_Ġkids   \n",
       "\n",
       "                 200           201          202         203       204  \\\n",
       "importance  7.388374      7.209621     7.118626    7.115748   7.05514   \n",
       "feature     tf_Ġcell  tf_Ġstudying  tf_Ġlearned  tf_Ġpeople  tf_Ġthey   \n",
       "\n",
       "                    205             206          207        208       209  \\\n",
       "importance     6.978959        6.890601     6.886446   6.645034  6.530092   \n",
       "feature     tf_Ġoptions  tf_Ġunderstand  tf_Ġexplore  tf_Ġoften  tf_Ġroad   \n",
       "\n",
       "                  210          211           212        213        214  \\\n",
       "importance   6.507767     6.349953      6.294907   6.280403   6.208178   \n",
       "feature     tf_Ġclear  tf_Ġexpress  tf_Ġmistakes  tf_Ġmeans  tf_Ġthank   \n",
       "\n",
       "                 215             216         217       218         219  \\\n",
       "importance  6.202746        6.104156    5.964964  5.837977    5.818327   \n",
       "feature      tf_Ġwho  tf_Ġadvantages  tf_Ġmatter  tf_Ġwhat  tf_Ġplanet   \n",
       "\n",
       "                 220       221       222           223       224       225  \\\n",
       "importance  5.815298  5.709992  5.631436      5.620426  5.614038  5.596033   \n",
       "feature     tf_Ġyour   tf_Ġmay  tf_Ġfeel  tf_Ġrequired   tf_Ġits   tf_Ġown   \n",
       "\n",
       "                     226          227           228          229       230  \\\n",
       "importance      5.529945     5.419085      5.402081     5.380029  5.340683   \n",
       "feature     tf_Ġbenefits  tf_Ġbelieve  tf_Ġprojects  tf_Ġteacher     tf_Ġ3   \n",
       "\n",
       "                 231       232                233          234       235  \\\n",
       "importance  5.328637  5.256274           5.252212      5.23568  5.208162   \n",
       "feature       tf_Ġis  tf_Ġhard  ts_words_per_sent  tf_Ġschools   tf_Ġbut   \n",
       "\n",
       "                 236        237       238       239          240       241  \\\n",
       "importance  5.194965   5.065253  4.885905  4.847053     4.773505  4.769887   \n",
       "feature      tf_Ġnot  tf_Ġagree   tf_Ġall    tf_Ġat  tf_Ġwhether   tf_Ġcan   \n",
       "\n",
       "                 242       243        244       245        246          247  \\\n",
       "importance  4.724706  4.714436    4.70049  4.694871   4.612142     4.607749   \n",
       "feature     tf_Ġmake    tf_Ġno  tf_Ġspend   tf_Ġwhy  tf_Ġfirst  tf_Ġexample   \n",
       "\n",
       "                  248       249       250        251       252          253  \\\n",
       "importance   4.582759  4.522965  4.480743   4.444437  4.342023     4.305319   \n",
       "feature     tf_Ġgoing  tf_Ġname  tf_Ġable  tf_Ġabout    tf_Ġto  tf_Ġhelping   \n",
       "\n",
       "                  254       255             256         257          258  \\\n",
       "importance    4.24401  4.198876        4.120795    4.090305     4.023343   \n",
       "feature     tf_Ġgiven   tf_Ġfor  tf_Ġactivities  tf_Ġsports  tf_Ġanother   \n",
       "\n",
       "                  259             260          261                      262  \\\n",
       "importance   3.994397        3.959758     3.944437                 3.885608   \n",
       "feature     tf_Ġlives  tf_Ġeverything  tf_Ġimagine  ts_flesch_kincaid_grade   \n",
       "\n",
       "                   263        264       265                       266  \\\n",
       "importance    3.847145    3.78024  3.763478                  3.714287   \n",
       "feature     tf_Ġsummer  tf_Ġthink   tf_Ġsay  ts_linsear_write_formula   \n",
       "\n",
       "                 267          268             269        270       271  \\\n",
       "importance  3.700971     3.526972        3.512095   3.493603  3.466834   \n",
       "feature      tf_Ġour  tf_Ġbenefit  va_valence_std  tf_Ġstart  tf_Ġfact   \n",
       "\n",
       "                         272       273       274       275             276  \\\n",
       "importance          3.453146  3.450044  3.433106  3.419986        3.397957   \n",
       "feature     va_dominance_std    tf_Ġan   tf_Ġbad   tf_Ġask  va_arousal_std   \n",
       "\n",
       "                 277          278       279       280          281        282  \\\n",
       "importance  3.395497     3.367174  3.367153  3.365255     3.361254   3.312541   \n",
       "feature     tf_Ġkeep  tf_Ġparents  tf_Ġgood  tf_Ġlast  tf_Ġstudies  tf_Ġtheir   \n",
       "\n",
       "                  283        284        285         286       287        288  \\\n",
       "importance   3.234521   3.197531   3.197361    3.196799  3.183557   3.144096   \n",
       "feature     tf_Ġworth  tf_Ġafter  tf_Ġgives  tf_Ġreason   tf_Ġnow  tf_Ġthese   \n",
       "\n",
       "                      289          290      291         292       293  \\\n",
       "importance       3.066222     2.936248  2.93553    2.911227  2.909382   \n",
       "feature     tf_Ġtherefore  tf_Ġinstead  tf_Ġone  tf_Ġaround   tf_Ġare   \n",
       "\n",
       "                 294       295          296       297        298       299  \\\n",
       "importance  2.902889  2.888231     2.874432   2.86217   2.849054  2.814121   \n",
       "feature      tf_Ġtoo   tf_Ġhow  tf_Ġaverage  tf_Ġknow  tf_Ġplace   tf_Ġfun   \n",
       "\n",
       "                  300       301        302       303        304       305  \\\n",
       "importance   2.794135  2.793975   2.791943   2.78416   2.773086  2.738538   \n",
       "feature     tf_Ġphone  tf_Ġwere  tf_Ġcause  tf_Ġlife  tf_Ġbeing  tf_Ġhome   \n",
       "\n",
       "                 306       307       308         309        310         311  \\\n",
       "importance  2.731679  2.711715  2.682313    2.680587   2.666754    2.652306   \n",
       "feature        tf_Ġa  tf_Ġthan    tf_Ġbe  tf_Ġrather  tf_Ġworld  tf_Ġhaving   \n",
       "\n",
       "                                       312       313        314       315  \\\n",
       "importance                         2.65118  2.642481   2.625511  2.625185   \n",
       "feature     ts_automated_readability_index    tf_Ġin  tf_Ġsense  tf_Ġdown   \n",
       "\n",
       "                 316                  317       318        319         320  \\\n",
       "importance  2.616417             2.590504  2.590005   2.567017    2.564539   \n",
       "feature     tf_Ġthis  ch_repeat_char_frac  tf_Ġthat  tf_Ġsince  tf_Ġothers   \n",
       "\n",
       "                 321       322       323       324         325        326  \\\n",
       "importance  2.542941  2.501905  2.483153  2.456413    2.449562   2.417475   \n",
       "feature      tf_Ġhis  tf_Ġstay  tf_Ġwith   tf_Ġout  tf_Ġbecome  tf_Ġdoing   \n",
       "\n",
       "                  327         328       329       330       331       332  \\\n",
       "importance   2.385181    2.373887   2.36267  2.347529   2.33098  2.329677   \n",
       "feature     tf_Ġallow  tf_Ġreally  tf_Ġwhen   tf_Ġtry  tf_Ġhigh   tf_Ġoff   \n",
       "\n",
       "                  333       334       335        336       337      338  \\\n",
       "importance   2.327633  2.265077  2.251067   2.200758  2.193883  2.19388   \n",
       "feature     tf_Ġteach     tf_Ġs  tf_Ġjust  tf_Ġthing  tf_Ġtime  tf_Ġway   \n",
       "\n",
       "                  339            340        341       342       343       344  \\\n",
       "importance   2.189415       2.165207   2.122313   2.11352  2.111507  2.108935   \n",
       "feature     tf_Ġstill  tf_Ġattention  tf_Ġwhich  tf_Ġtake   tf_Ġput    tf_Ġup   \n",
       "\n",
       "                 345        346          347        348       349       350  \\\n",
       "importance  2.073899   2.062941     2.042671   2.038351  2.037022  2.026715   \n",
       "feature      tf_Ġany  tf_Ġthere  tf_Ġwithout  tf_Ġother  tf_Ġhave  tf_Ġmore   \n",
       "\n",
       "               351       352       353       354         355       356  \\\n",
       "importance   2.002  1.994819  1.905548  1.902783    1.895117  1.878437   \n",
       "feature     tf_Ġof  tf_Ġeven    tf_Ġor  tf_Ġbeen  tf_Ġtaking   tf_Ġsee   \n",
       "\n",
       "                    357         358       359       360       361       362  \\\n",
       "importance     1.869759    1.838896   1.81638  1.790969  1.787349  1.784771   \n",
       "feature     tf_Ġimprove  tf_Ġbetter  tf_Ġdone  tf_Ġsame    tf_Ġon  tf_Ġthem   \n",
       "\n",
       "                 363        364       365       366            367       368  \\\n",
       "importance  1.781002   1.776031  1.745369  1.716723       1.716033  1.697812   \n",
       "feature      tf_Ġuse  tf_Ġtimes  tf_Ġsuch  tf_Ġfrom  tf_Ġdifferent    tf_Ġas   \n",
       "\n",
       "                 369       370       371       372        373      374  \\\n",
       "importance  1.693832   1.69218  1.690742  1.672335   1.666259  1.65098   \n",
       "feature     tf_Ġwant  tf_Ġgive  tf_Ġidea  tf_Ġhelp  tf_Ġusing  tf_Ġnew   \n",
       "\n",
       "                  375       376         377        378       379       380  \\\n",
       "importance   1.637237  1.627404    1.561339   1.559408  1.554674  1.518231   \n",
       "feature     tf_Ġmakes  tf_Ġonly  tf_Ġperson  tf_Ġevery  tf_Ġmade  tf_Ġalso   \n",
       "\n",
       "                   381       382       383       384       385       386  \\\n",
       "importance    1.497944  1.483841  1.480845  1.459464  1.442078  1.425265   \n",
       "feature     tf_Ġthings  tf_Ġeach  tf_Ġsome   tf_Ġjob  tf_Ġless   tf_Ġlot   \n",
       "\n",
       "                 387          388           389         390        391  \\\n",
       "importance  1.293403     1.277447      1.265386    1.251879   1.138635   \n",
       "feature     tf_Ġsaid  tf_Ġfriends  tf_Ġactually  tf_Ġduring  tf_Ġgreat   \n",
       "\n",
       "                  392        393        394        395        396  \\\n",
       "importance   1.136488   1.079514   1.023715   1.015635   1.003615   \n",
       "feature     tf_Ġclass  tf_Ġmaybe  tf_Ġthose  tf_Ġnever  tf_Ġwhere   \n",
       "\n",
       "                    397            398       399       400         401  \\\n",
       "importance     0.979889       0.976981  0.897438  0.889641    0.864037   \n",
       "feature     tf_Ġsomeone  tf_Ġsomething    tf_Ġby  tf_Ġaway  tf_Ġmaking   \n",
       "\n",
       "                 402          403       404       405         406         407  \n",
       "importance  0.756007     0.705514  0.668125  0.633369    0.545553    0.545249  \n",
       "feature     tf_Ġinto  tf_Ġthrough  tf_Ġtell   tf_Ġgas  tf_Ġlikely  tf_Ġfuture  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores = model.get_score(importance_type=\"gain\")\n",
    "assert len(scores)!=0\n",
    "rows = []\n",
    "for feature, score in scores.items():\n",
    "    rows.append({'importance': score, 'feature': feature})\n",
    "idf = pd.DataFrame.from_records(rows)\n",
    "idf = idf.sort_values([\"importance\"], ascending=False, ignore_index=True)\n",
    "fp = f\"{job_dir}/importance.csv\"\n",
    "idf.to_csv(fp, index=True)\n",
    "print(f\"Saved {fp}\")\n",
    "idf.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a994ecf2-2058-4117-923f-bda3a05f83f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:17:24.858528\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
